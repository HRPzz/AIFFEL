{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. 사람의 몸짓을 읽어보자\n",
    "\n",
    "**Human pose estimation에 대해 그동안 발표된 논문을 기반으로 아이디어의 흐름이 발전해 온 내역을 자세히 살펴본다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15-1. 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15-2. body language, 몸으로 하는 대화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15-3. Pose 는 face landmark 랑 비슷해요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15-4. human keypoint detection (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15-5. human keypoint detection (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15-6. 코드로 이해하는 pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "resnet = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upconv1 = tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same')\n",
    "bn1 = tf.keras.layers.BatchNormalization()\n",
    "relu1 = tf.keras.layers.ReLU()\n",
    "upconv2 = tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same')\n",
    "bn2 = tf.keras.layers.BatchNormalization()\n",
    "relu2 = tf.keras.layers.ReLU()\n",
    "upconv3 = tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same')\n",
    "bn3 = tf.keras.layers.BatchNormalization()\n",
    "relu3 = tf.keras.layers.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_deconv_layer(num_deconv_layers):\n",
    "    seq_model = tf.keras.models.Sequential()\n",
    "    for i in range(num_deconv_layers):\n",
    "        seq_model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same'))\n",
    "        seq_model.add(tf.keras.layers.BatchNormalization())\n",
    "        seq_model.add(tf.keras.layers.ReLU())\n",
    "    return seq_model\n",
    "\n",
    "upconv = _make_deconv_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = tf.keras.layers.Conv2D(17, kernel_size=(1,1), padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(256, 192, 3))\n",
    "x = resnet(inputs)\n",
    "x = upconv(x)\n",
    "out = final_layer(x)\n",
    "model = keras.Model(inputs, out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_input = np.zeros((1,256,192,3), dtype=np.float32)\n",
    "tf_input = tf.convert_to_tensor(np_input, dtype=tf.float32)\n",
    "print('input shape')\n",
    "print (tf_input.shape)\n",
    "print('\\n')\n",
    "\n",
    "tf_output = model(tf_input)\n",
    "print('output shape')\n",
    "print (tf_output.shape)\n",
    "print (tf_output[0,:10,:10,:10])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiffel_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
