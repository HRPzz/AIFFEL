{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 이미지 어디까지 우려볼까?\n",
    "\n",
    "**텐서플로우의 random augmentation 기법을 적용해 보고, 최신 augmentation 기법을 익힌다. 직접 모델을 학습시켜 비교 실험을 진행해 본다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mkdir -p ~/aiffel/data_augmentation/data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. Augmentation 적용 (1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3. Augmentation 적용 (2) Augmentation 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    # Normalizes images: `uint8` -> `float32`\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image,label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    return image, label\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋(ds)을 가공하는 메인함수\n",
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16, with_aug=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img,  # 기본적인 전처리 함수 적용\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    if not is_test and with_aug:\n",
    "        ds = ds.map(\n",
    "            augment,       # augment 함수 적용\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make random augment function\n",
    "def augment2(image,label):\n",
    "    # [[YOUR CODE]]\n",
    "    image = tf.image.central_crop(image, np.random.uniform(0.50, 1.00))\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4. Augmentation 적용 (3) 비교실험 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "resnet50 = keras.models.Sequential([\n",
    "    keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg',\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_resnet50 = keras.models.Sequential([\n",
    "    keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg',\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "ds_train_no_aug = apply_normalize_on_dataset(ds_train, with_aug=False)\n",
    "ds_train_aug = apply_normalize_on_dataset(ds_train, with_aug=True)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, is_test=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPOCH = 20  # Augentation 적용 효과를 확인하기 위해 필요한 epoch 수\n",
    "EPOCH = 3\n",
    "\n",
    "resnet50.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet50_no_aug = resnet50.fit(\n",
    "    ds_train_no_aug, # augmentation 적용하지 않은 데이터셋 사용\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_resnet50.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet50_aug = aug_resnet50.fit(\n",
    "    ds_train_aug, # augmentation 적용한 데이터셋 사용\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_resnet50_no_aug.history['val_accuracy'], 'r')\n",
    "plt.plot(history_resnet50_aug.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['No Augmentation', 'With Augmentation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_resnet50_no_aug.history['val_accuracy'], 'r')\n",
    "plt.plot(history_resnet50_aug.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['No Augmentation', 'With Augmentation'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.ylim(0.50, 0.80)    # 출력하고자 하는  Accuracy 범위를 지정해 주세요. \n",
    "#plt.ylim(0.72, 0.76)  # EPOCH=20으로 진행한다면 이 범위가 적당합니다. \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-5. 심화 기법 (1) Cutmix Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터셋에서 이미지 2개를 가져옵니다. \n",
    "for i, (image, label) in enumerate(ds_train_no_aug.take(1)):\n",
    "    if i == 0:\n",
    "        image_a = image[0]\n",
    "        image_b = image[1]\n",
    "        label_a = label[0]\n",
    "        label_b = label[1]\n",
    "        break\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image_a)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(image_b)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_box(image_a, image_b):\n",
    "    # image.shape = (height, width, channel)\n",
    "    image_size_x = image_a.shape[1]\n",
    "    image_size_y = image_a.shape[0]\n",
    "    \n",
    "    # get center of box\n",
    "    x = tf.cast(tf.random.uniform([], 0, image_size_x), tf.int32)\n",
    "    y = tf.cast(tf.random.uniform([], 0, image_size_y), tf.int32)\n",
    "\n",
    "    # get width, height of box\n",
    "    width = tf.cast(image_size_x*tf.math.sqrt(1-tf.random.uniform([], 0, 1)), tf.int32)\n",
    "    height = tf.cast(image_size_y*tf.math.sqrt(1-tf.random.uniform([], 0, 1)), tf.int32)\n",
    "    \n",
    "    # clip box in image and get minmax bbox\n",
    "    x_min = tf.math.maximum(0, x-width//2)\n",
    "    y_min = tf.math.maximum(0, y-height//2)\n",
    "    x_max = tf.math.minimum(image_size_x, x+width//2)\n",
    "    y_max = tf.math.minimum(image_size_y, y+width//2)\n",
    "    \n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "x_min, y_min, x_max, y_max = get_clip_box(image_a, image_b)\n",
    "\n",
    "print('x : ', x_min, x_max)\n",
    "print('y : ', y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix two images\n",
    "def mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max):\n",
    "    image_size_x = image_a.shape[1]\n",
    "    image_size_y = image_a.shape[0] \n",
    "    middle_left = image_a[y_min:y_max, 0:x_min, :] # image_b의 왼쪽 바깥 영역\n",
    "    middle_center = image_b[y_min:y_max, x_min:x_max, :]  # image_b의 안쪽 영역\n",
    "    middle_right = image_a[y_min:y_max, x_max:image_size_x, :] # image_b의 오른쪽 바깥 영역\n",
    "    middle = tf.concat([middle_left,middle_center,middle_right], axis=1)\n",
    "    top = image_a[0:y_min, :, :]\n",
    "    bottom = image_a[y_max:image_size_y, :, :]\n",
    "    mixed_img = tf.concat([top, middle, bottom],axis=0)\n",
    "    \n",
    "    return mixed_img\n",
    "\n",
    "mixed_img = mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max)\n",
    "plt.imshow(mixed_img.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix two labels\n",
    "def mix_2_labels(label_a, label_b, x_min, y_min, x_max, y_max, num_classes=120):\n",
    "    image_size_x = image_a.shape[1]\n",
    "    image_size_y = image_a.shape[0] \n",
    "    mixed_area = (x_max-x_min)*(y_max-y_min)\n",
    "    total_area = image_size_x*image_size_y\n",
    "    ratio = tf.cast(mixed_area/total_area, tf.float32)\n",
    "\n",
    "    if len(label_a.shape)==0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape)==0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_label = (1-ratio)*label_a + ratio*label_b\n",
    "    return mixed_label\n",
    "\n",
    "mixed_label = mix_2_labels(label_a, label_b, x_min, y_min, x_max, y_max)\n",
    "mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([],0, batch_size),tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        x_min, y_min, x_max, y_max = get_clip_box(image_a, image_b)\n",
    "        mixed_imgs.append(mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max))\n",
    "        mixed_labels.append(mix_2_labels(label_a, label_b, x_min, y_min, x_max, y_max))\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-6. 심화 기법 (2) Mixup Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for mixup\n",
    "def mixup_2_images(image_a, image_b, label_a, label_b):\n",
    "    ratio = tf.random.uniform([], 0, 1)\n",
    "    \n",
    "    if len(label_a.shape)==0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape)==0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_image= (1-ratio)*image_a + ratio*image_b\n",
    "    mixed_label = (1-ratio)*label_a + ratio*label_b\n",
    "    \n",
    "    return mixed_image, mixed_label\n",
    "\n",
    "mixed_img, mixed_label = mixup_2_images(image_a, image_b, label_a, label_b)\n",
    "plt.imshow(mixed_img.numpy())\n",
    "plt.show()\n",
    "print(mixed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([],0,batch_size), tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        mixed_img, mixed_label = mixup_2_images(image_a, image_b, label_a, label_b)\n",
    "        mixed_imgs.append(mixed_img)\n",
    "        mixed_labels.append(mixed_label)\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-7. 프로젝트: CutMix 또는 Mixup 비교실험 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    # Normalizes images: `uint8` -> `float32`\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    return image, label\n",
    "\n",
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16, with_aug=False, with_cutmix=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    if not is_test and with_aug:\n",
    "        ds = ds.map(\n",
    "            augment\n",
    "        )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test and with_cutmix:\n",
    "        ds = ds.map(\n",
    "            cutmix,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    else:\n",
    "        ds = ds.map(\n",
    "            onehot,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **루브릭**\n",
    ">\n",
    ">|번호|평가문항|상세기준|\n",
    ">|:---:|---|---|\n",
    ">|1|CutMix와 MixUp 기법을 ResNet50 분류기에 성공적으로 적용하였는가?|CutMix와 MixUp을 적용한 데이터셋으로 훈련한 각각의 ResNet 모델이 수렴하였다.|\n",
    ">|2|다양한 실험을 통해 태스크에 최적인 Augmentation 기법을 찾아내었는가?|Augmentation 적용을 통해 Augmentaion 미적용시 대비 5% 이상의 성능향상을 확인함|\n",
    ">|3|여러가지 Augmentation 기법을 적용한 결과를 체계적으로 비교분석하였는가?|기본 Augmentation, CutMix, MixUp이 적용된 결과를 시각화와 함께 체계적으로 분석하였다.|"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiffel_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
