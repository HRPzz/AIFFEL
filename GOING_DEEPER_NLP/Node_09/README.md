# 9. Transformer가 나오기까지

**어텐션(Attention) 기법을 간단히 복습한 후, 이를 활용한 트랜스포머(Transformer)에 포함된 모듈을 심층적으로 이해한다. 트랜스포머를 발전시키기 위해 적용된 테크닉도 간략히 알아본다.**

---

|-|목차|⏲ 210분|
|:---:|---|:---:|
|9-1| 들어가며 | 5분|
|9-2| 우리가 만드는 언어 모델 | 15분|
|9-3| Sequence to Sequence 문제 | 20분|
|9-4| Sequence to Sequence 구현 | 30분|
|9-5| Attention! (1) Bahdanau Attention | 60분|
|9-6| Attention! (2) Luong Attention | 25분|
|9-7| 트랜스포머로 가기 전 징검다리? | 30분|
|9-8| 트랜스포머, 그 후엔 | 20분
|9-8| 마무리 | 5분|

---

## 학습 목표

- 트랜스포머 이전의 Attention 기법에 대해 간단하게 복습한다.
- 트랜스포머에 포함된 모듈들을 심층적으로 이해한다.
- 트랜스포머를 발전시키기 위해 적용된 여러 테크닉들을 알아본다.
