# 5. 나의 첫 번째 캐글 경진대회, 무작정 따라해보기

**캐글 경진대회에 직접 참가해 대회의 규칙과 분위기를 살펴보는 것부터, 머신러닝을 활용해서 모델을 학습시킨 뒤 제출하고 내 랭킹을 확인해보는 것까지, 캐글 경진대회를 위한 전과정을 체험해 본다.**

- 캐글코리아(Kaggle Korea)가 2019년에 주최했던 캐글 경진대회인 2019 2nd ML month with KaKR를 처음부터 끝까지 직접 경험
- 캐글(Kaggle): 데이터 사이언티스트들을 위한 경진대회 사이트
  - 캐글의 커널(Kernel): 주피터 노트북 파일(Baseline 커널 파일)이 캐글 서버에서 실행될 때 그 프로그램을 일컫는 개념

---

|-|목차|⏲ 360분|
|:---:|---|:---:|
|5-1| 들어가며 | 5분|
|5-2| 대회의 시작 (1) 참가 규칙, 평가 기준 살펴보기 | 10분|
|5-3| 대회의 시작 (2) 데이터 살펴보기 | 10분|
|5-4| 일단 제출하고 시작해! Baseline 모델 (1) Baseline 셋팅하기 | 10분|
|5-5| 일단 제출하고 시작해! Baseline 모델 (2) 라이브러리, 데이터 가져오기 | 5분|
|5-6| 일단 제출하고 시작해! Baseline 모델 (3) 데이터 이해하기 | 20분|
|5-7| 일단 제출하고 시작해! Baseline 모델 (4) 모델 설계 | 20분|
|5-8| 일단 제출하고 시작해! Baseline 모델 (5) 캐글에 첫 결과 제출하기 | 10분|
|5-9| 랭킹을 올리고 싶다면? (1) 다시 한 번, 내 입맛대로 데이터 준비하기 | 10분|
|5-10| 랭킹을 올리고 싶다면? (2) 다양한 실험을 위해 함수로 만들어 쓰자 | 20분|
|5-11| 랭킹을 올리고 싶다면? (3) 하이퍼 파라미터 튜닝의 최강자, 그리드 탐색 | 40분|
|5-12| 랭킹을 올리고 싶다면? (4) 제출하는 것도, 빠르고 깔끔하게! | 20분|
|5-13| 프로젝트 : This is your playground! Leaderboard를 정복해 주세요! | 180분|
|5-14| 프로젝트 제출|-|

---

## 학습 목표

- 데이터 사이언스 관련 최대 커뮤니티인 캐글의 경진대회에 직접 참여해서 문제를 해결해본다.
- 캐글에서 데이터를 내려받는 것으로부터 시작해서, 로컬 서버에서 자유롭게 다루어보며 문제 해결을 위한 고민을 해본다.
- 앙상블 기법의 개념과 강점을 이해하고, 여러 모델의 예측 결과를 Averaging 한 최종 결과로 캐글에 제출해본다.
- 하이퍼 파라미터 튜닝의 필요성과 의미를 이해하고, Grid Search, Random Search 등의 기법을 알아본다.
- Grid Search 기법을 활용해서 직접 하이퍼 파라미터 튜닝 실험을 해보고, 모델의 성능을 최대한 끌어올려본다.

## 학습 전제

- 정형 데이터를 활용해 EDA와 간단한 분류, 회귀 문제를 해결해본 적이 있다.
- numpy, pandas, matplotlib을 활용해 정형 데이터를 자유자재로 다룰 수 있다.
- 정형 데이터를 활용해 다양한 모델을 학습시켜보고, 예측 결과를 도출하는 것까지의 과정을 코드로 진행할 수 있다.

## 목차

- 대회의 시작: 참가 규칙과 데이터, 평가 기준 살펴보기
- 자 그럼, 일단 제출하고 시작해! Baseline은 여기 있으니까!
- 랭킹을 올리고 싶다면? 최적의 모델을 찾아서, 하이퍼 파라미터 튜닝
- 프로젝트: This is your playground! Leaderboard를 정복해주세요!

## 준비물

- 회귀 모델을 구현 라이브러리: xgboost, lightgbm
- 결측 데이터를 확인 라이브러리: missingno

---

## 5-13. 프로젝트 : This is your playground! Leaderboard를 정복해 주세요

캐글에서의 성적 또는 모델의 성능을 최대화 하기

=> 직접 다양한 하이퍼 파라미터를 튜닝하며 최적의 조합을 찾아보기

- ✓ 튜닝해볼 수 있는 모델 클래스 인자
  - 대표적으로 자주 튜닝하는 lightgbm 라이브러리의 인자
    - max_depth : 의사 결정 나무의 깊이, 정수 사용
    - learning_rate : 한 스텝에 이동하는 양을 결정하는 파라미터, 보통 0.0001~0.1 사이의 실수 사용
    - n_estimators : 사용하는 개별 모델의 개수, 보통 50~100 이상의 정수 사용
    - num_leaves : 하나의 LightGBM 트리가 가질 수 있는 최대 잎의 수
    - boosting_type : 부스팅 방식, gbdt, rf 등의 문자열 입력
  - lightgbm, xgboost 하이퍼 파라미터 튜닝 키워드로 검색으로 다양한 하이퍼 파라미터의 종류 확인 가능
- ✓ 시도해볼 수 있는 방법
  - 시도할 방법
    - 기존에 있는 데이터의 피처를 모델을 보다 잘 표현할 수 있는 형태로 처리하기 (피처 엔지니어링)
    - LGBMRegressor, XGBRegressor, RandomForestRegressor 세 가지 이상의 다양한 모델에 대해 하이퍼 파라미터 튜닝하기
    - 다양한 하이퍼 파라미터에 대해 그리드 탐색을 시도해서 최적의 조합을 찾아보기
    - Baseline 커널에서 활용했던 블렌딩 방법 활용하기
  - 그 외 방법
    - 도움되는 가장 좋은 자료: 대회를 진행한 다른 사람들이 올려둔 커널
      - e.g. 스태킹 앙상블(stacking ensemble) 등의 기법을 활용한 커널
    - 결과 csv는 캐글에, 사용한 노트북은 깃허브(GitHub)를 통해 이곳에 제출. 제출한 노트북에는 본인의 캐글 Submission 스코어를 기재하기
- 프로젝트 루브릭
  - 데이터 전처리, 모델학습, 예측의 전체 과정을 거쳐 캐글 submission까지 전과정이 성공적으로 진행되었는가?
  - 제출된 노트북이 캐글 커널로 사용될 수 있을 만큼 전처리, 학습, 최적화 진행 과정이 체계적으로 기술되었는가?
  - 다양한 피처 엔지니어링과 하이퍼 파라미터 튜닝 등의 최적화 기법을 통해 캐글 리더보드의 Private score 기준 110000 이하의 점수를 얻었는가?

---

>## **루브릭**

>|번호|평가문항|상세기준|평가결과|
>|:---:|---|---|:---:|
>|1|캐글 데이터분석 전과정이 성공적으로 진행되었는가?|데이터 전처리, 모델학습, 예측의 전체 과정을 거쳐 캐글 submission까지 진행되었다.|⭐|
>|2|전처리, 학습과정 및 결과에 대한 설명이 시각화를 포함하여 체계적으로 진행되었는가?|제출된 노트북이 캐글 커널로 사용될 수 있을 만큼 전처리, 학습, 최적화 진행 과정이 체계적으로 기술되었다.|⭐|
>|3|회귀모델 예측정확도가 기준 이상 높게 나왔는가?|다양한 피처 엔지니어링과 하이퍼 파라미터 튜닝 등의 최적화 기법을 통해 캐글 리더보드의 Private score 기준 110000 이하의 점수를 얻었다.|☆|
