{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ë‚˜ì˜ ì²« ë²ˆì§¸ ìºê¸€ ê²½ì§„ëŒ€íšŒ, ë¬´ì‘ì • ë”°ë¼í•´ë³´ê¸°\n",
    "\n",
    "**ìºê¸€ ê²½ì§„ëŒ€íšŒì— ì§ì ‘ ì°¸ê°€í•´ ëŒ€íšŒì˜ ê·œì¹™ê³¼ ë¶„ìœ„ê¸°ë¥¼ ì‚´í´ë³´ëŠ” ê²ƒë¶€í„°, ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•´ì„œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ ë’¤ ì œì¶œí•˜ê³  ë‚´ ë­í‚¹ì„ í™•ì¸í•´ë³´ëŠ” ê²ƒê¹Œì§€, ìºê¸€ ê²½ì§„ëŒ€íšŒë¥¼ ìœ„í•œ ì „ê³¼ì •ì„ ì²´í—˜í•´ ë³¸ë‹¤.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. ë“¤ì–´ê°€ë©°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ conda list | grep xgboost\n",
    "$ conda list | grep lightgbm\n",
    "$ conda list | grep missingno\n",
    "$ pip list | grep scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mkdir -p ~/aiffel/kaggle_kakr_housing\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. ëŒ€íšŒì˜ ì‹œì‘ (1) ì°¸ê°€ ê·œì¹™, í‰ê°€ ê¸°ì¤€ ì‚´í´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. ëŒ€íšŒì˜ ì‹œì‘ (2) ë°ì´í„° ì‚´í´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mkdir -p ~/aiffel/kaggle_kakr_housing/data\n",
    "$ ln -s ~/data/data/*.csv ~/aiffel/kaggle_kakr_housing/data\n",
    "$ ls ~/aiffel/kaggle_kakr_housing/data  # ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ í™•ì¸\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4. ì¼ë‹¨ ì œì¶œí•˜ê³  ì‹œì‘í•´! Baseline ëª¨ë¸ (1) Baseline ì…‹íŒ…í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ conda install -c conda-forge xgboost=1.3.3\n",
    "$ conda install -c conda-forge lightgbm=3.1.1 \n",
    "$ conda install -c conda-forge missingno=0.4.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-5. ì¼ë‹¨ ì œì¶œí•˜ê³  ì‹œì‘í•´! Baseline ëª¨ë¸ (2) ë¼ì´ë¸ŒëŸ¬ë¦¬, ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "sub_data_path = join(data_dir, 'test.csv')      # í…ŒìŠ¤íŠ¸, ì¦‰ submission ì‹œ ì‚¬ìš©í•  ë°ì´í„° ê²½ë¡œ\n",
    "\n",
    "print(train_data_path)\n",
    "print(sub_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-6. ì¼ë‹¨ ì œì¶œí•˜ê³  ì‹œì‘í•´! Baseline ëª¨ë¸ (3) ë°ì´í„° ì´í•´í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)\n",
    "print('train data dim : {}'.format(data.shape))\n",
    "print('sub data dim : {}'.format(sub.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "del data['price']\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(data)\n",
    "data = pd.concat((data, sub), axis=0)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. id ì»¬ëŸ¼ì´ ê²°ì¸¡ì¹˜ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "null_check = pd.isnull(data['id'])\n",
    "print(null_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ê²°ì¸¡ì¹˜ì¸ ë°ì´í„°ë§Œ ë½‘ì•„ëƒ…ë‹ˆë‹¤.\n",
    "null_data = data.loc[null_check, 'id']\n",
    "null_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ê²°ì¸¡ì¹˜ì¸ ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤.\n",
    "print('{}: {}'.format('id', len(null_data.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œ ë²ˆì— ë¿…!\n",
    "print('{} : {}'.format('id', len(data.loc[pd.isnull(data['id']), 'id'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date'].apply(lambda x : str(x[:6]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9, 2, figsize=(12, 50))   # ê°€ë¡œìŠ¤í¬ë¡¤ ë•Œë¬¸ì— ê·¸ë˜í”„ í™•ì¸ì´ ë¶ˆí¸í•˜ë‹¤ë©´ figsizeì˜ xê°’ì„ ì¡°ì ˆí•´ ë³´ì„¸ìš”. \n",
    "\n",
    "# id ë³€ìˆ˜(count==0ì¸ ê²½ìš°)ëŠ” ì œì™¸í•˜ê³  ë¶„í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15', 'sqft_living15']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(12, 24))\n",
    "\n",
    "count = 0\n",
    "for row in range(4):\n",
    "    for col in range(2):\n",
    "        if count == 7:\n",
    "            break\n",
    "        sns.kdeplot(data=data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 10, 500)\n",
    "yy = np.log(xx)\n",
    "\n",
    "plt.hlines(0, 0, 10)\n",
    "plt.vlines(0, -5, 5)\n",
    "plt.plot(xx, yy, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_transformation = np.log1p(y)\n",
    "\n",
    "sns.kdeplot(y_log_transformation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = data.iloc[train_len:, :]\n",
    "x = data.iloc[:train_len, :]\n",
    "\n",
    "print(x.shape)\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-7. ì¼ë‹¨ ì œì¶œí•˜ê³  ì‹œì‘í•´! Baseline ëª¨ë¸ (4) ëª¨ë¸ ì„¤ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=2019)\n",
    "xgboost = xgb.XGBRegressor(random_state=2019)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=2019)\n",
    "\n",
    "models = [{'model':gboost, 'name':'GradientBoosting'}, {'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'}]\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_score(models):\n",
    "    kfold = KFold(n_splits=5).get_n_splits(x.values)\n",
    "    for m in models:\n",
    "        CV_score = np.mean(cross_val_score(m['model'], X=x.values, y=y, cv=kfold))\n",
    "        print(f\"Model: {m['name']}, CV score:{CV_score:.4f}\")\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_score(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AveragingBlending(models, x, y, sub_x):\n",
    "    for m in models : \n",
    "        m['model'].fit(x.values, y)\n",
    "    \n",
    "    predictions = np.column_stack([\n",
    "        m['model'].predict(sub_x.values) for m in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = AveragingBlending(models, x, y, sub)\n",
    "print(len(y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'id' : sub_id, \n",
    "    'price' : y_pred\n",
    "})\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission_path = join(data_dir, 'submission.csv')\n",
    "result.to_csv(my_submission_path, index=False)\n",
    "\n",
    "print(my_submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-8. ì¼ë‹¨ ì œì¶œí•˜ê³  ì‹œì‘í•´! Baseline ëª¨ë¸ (5) ìºê¸€ì— ì²« ê²°ê³¼ ì œì¶œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-9. ë­í‚¹ì„ ì˜¬ë¦¬ê³  ì‹¶ë‹¤ë©´? (1) ë‹¤ì‹œ í•œ ë²ˆ, ë‚´ ì…ë§›ëŒ€ë¡œ ë°ì´í„° ì¤€ë¹„í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "test_data_path = join(data_dir, 'test.csv') \n",
    "\n",
    "train = pd.read_csv(train_data_path)\n",
    "test = pd.read_csv(test_data_path)\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['date'].apply(lambda i: i[:6]).astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['price']\n",
    "del train['price']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['id']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date'] = test['date'].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "del test['id']\n",
    "\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "seabornì˜ `kdeplot`ì„ í™œìš©í•´ `y`ì˜ ë¶„í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!\n",
    "\"\"\"\n",
    "\n",
    "#ì½”ë“œ ì‘ì„±\n",
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-10. ë­í‚¹ì„ ì˜¬ë¦¬ê³  ì‹¶ë‹¤ë©´? (2) ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ìœ„í•´ í•¨ìˆ˜ë¡œ ë§Œë“¤ì–´ ì“°ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_stateëŠ” ëª¨ë¸ì´ˆê¸°í™”ë‚˜ ë°ì´í„°ì…‹ êµ¬ì„±ì— ì‚¬ìš©ë˜ëŠ” ëœë¤ ì‹œë“œê°’ì…ë‹ˆë‹¤. \n",
    "#random_state=None    # ì´ê²Œ ì´ˆê¸°ê°’ì…ë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ì§€ì •í•˜ì§€ ì•Šê³  Noneì„ ë„˜ê²¨ì£¼ë©´ ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì„ì˜ë¡œ ì„ íƒí•©ë‹ˆë‹¤.  \n",
    "random_state=2020        # í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì´ë ‡ê²Œ ê³ ì •ê°’ì„ ì„¸íŒ…í•´ ë‘ê² ìŠµë‹ˆë‹¤. \n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "for model in models:\n",
    "    # ëª¨ë¸ ì´ë¦„ íšë“\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # train, test ë°ì´í„°ì…‹ ë¶„ë¦¬ - ì—¬ê¸°ì—ë„ random_stateë¥¼ ê³ ì •í•©ë‹ˆë‹¤. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ì˜ rmseê°’ ì €ì¥\n",
    "    df[model_name] = rmse(y_test, y_pred)\n",
    "    \n",
    "    # data frameì— ì €ì¥\n",
    "    score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(models, train, y):\n",
    "    # ë‹µì•ˆ ì‘ì„±\n",
    "    df = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        df[model_name] = rmse(y_test, y_pred)\n",
    "        score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "            \n",
    "    return score_df\n",
    "    \n",
    "get_scores(models, train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-11. ë­í‚¹ì„ ì˜¬ë¦¬ê³  ì‹¶ë‹¤ë©´? (3) í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì˜ ìµœê°•ì, ê·¸ë¦¬ë“œ íƒìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state)\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "grid_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = grid_model.cv_results_['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = grid_model.cv_results_['mean_test_score']\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "results = pd.DataFrame(params)\n",
    "results['score'] = score\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['RMSE'] = np.sqrt(-1 * results['score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.rename(columns={'RMSE': 'RMSLE'})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ„ì˜ í‘œë¥¼ `RMSLE`ê°€ ë‚®ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•´ì£¼ì„¸ìš”.\n",
    "results = results.sort_values(by='RMSLE')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ì§„í–‰í•  ìˆ˜ ìˆëŠ” `my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)` í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ ë³´ì„¸ìš”.\n",
    "\n",
    "1. GridSearchCV ëª¨ë¸ë¡œ `model`ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "2. ëª¨ë¸ì„ fitting í•©ë‹ˆë‹¤.\n",
    "3. params, scoreì— ê° ì¡°í•©ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. \n",
    "4. ë°ì´í„° í”„ë ˆì„ì„ ìƒì„±í•˜ê³ , RMSLE ê°’ì„ ì¶”ê°€í•œ í›„ ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬í•œ `results`ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "# ì½”ë“œ ì…ë ¥\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
    "    # GridSearchCV ëª¨ë¸ë¡œ ì´ˆê¸°í™”\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "    \n",
    "    # ëª¨ë¸ fitting\n",
    "    grid_model.fit(train, y)\n",
    "\n",
    "    # ê²°ê³¼ê°’ ì €ì¥\n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "    \n",
    "    # ë°ì´í„° í”„ë ˆì„ ìƒì„±\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "    \n",
    "    # RMSLE ê°’ ê³„ì‚° í›„ ì •ë ¬\n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-12. ë­í‚¹ì„ ì˜¬ë¦¬ê³  ì‹¶ë‹¤ë©´? (4) ì œì¶œí•˜ëŠ” ê²ƒë„, ë¹ ë¥´ê³  ê¹”ë”í•˜ê²Œ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(random_state=random_state)\n",
    "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(max_depth=10, n_estimators=100, random_state=random_state)\n",
    "model.fit(train, y)\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.expm1(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['price'] = prediction\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, 'lgbm', '0.164399')\n",
    "submission.to_csv(submission_csv_path, index=False)\n",
    "print(submission_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ì•„ë˜ì˜ ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” `save_submission(model, train, y, test, model_name, rmsle)` í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ ì£¼ì„¸ìš”.\n",
    "1. ëª¨ë¸ì„ `train`, `y`ë¡œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "2. `test`ì— ëŒ€í•´ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "3. ì˜ˆì¸¡ê°’ì„ `np.expm1`ìœ¼ë¡œ ë³€í™˜í•˜ê³ , `submission_model_name_RMSLE_100000.csv` í˜•íƒœì˜ `csv` íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "# ì½”ë“œ ì‘ì„±\n",
    "def save_submission(model, train, y, test, model_name, rmsle):\n",
    "    model.fit(train, y)\n",
    "    prediction = model.predict(test)\n",
    "    prediction = np.expm1(prediction)\n",
    "    data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission['price'] = prediction\n",
    "    submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, model_name, rmsle)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(model, train, y, test, 'lgbm', rmsle='0.0168')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-13. í”„ë¡œì íŠ¸ : This is your playground! Leaderboardë¥¼ ì •ë³µí•´ ì£¼ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import lightgbm\n",
    "import missingno\n",
    "import sklearn\n",
    "\n",
    "print(xgboost.__version__)\n",
    "print(lightgbm.__version__)\n",
    "print(missingno.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## **ë£¨ë¸Œë¦­**\n",
    "\n",
    ">|ë²ˆí˜¸|í‰ê°€ë¬¸í•­|ìƒì„¸ê¸°ì¤€|\n",
    ">|:---:|---|---|\n",
    ">|1|ìºê¸€ ë°ì´í„°ë¶„ì„ ì „ê³¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆëŠ”ê°€?|ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸í•™ìŠµ, ì˜ˆì¸¡ì˜ ì „ì²´ ê³¼ì •ì„ ê±°ì³ ìºê¸€ submissionê¹Œì§€ ì§„í–‰ë˜ì—ˆë‹¤.|\n",
    ">|2|ì „ì²˜ë¦¬, í•™ìŠµê³¼ì • ë° ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª…ì´ ì‹œê°í™”ë¥¼ í¬í•¨í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆëŠ”ê°€?|ì œì¶œëœ ë…¸íŠ¸ë¶ì´ ìºê¸€ ì»¤ë„ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆì„ ë§Œí¼ ì „ì²˜ë¦¬, í•™ìŠµ, ìµœì í™” ì§„í–‰ ê³¼ì •ì´ ì²´ê³„ì ìœ¼ë¡œ ê¸°ìˆ ë˜ì—ˆë‹¤.|\n",
    ">|3|íšŒê·€ëª¨ë¸ ì˜ˆì¸¡ì •í™•ë„ê°€ ê¸°ì¤€ ì´ìƒ ë†’ê²Œ ë‚˜ì™”ëŠ”ê°€?|ë‹¤ì–‘í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ê³¼ í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ ë“±ì˜ ìµœì í™” ê¸°ë²•ì„ í†µí•´ ìºê¸€ ë¦¬ë”ë³´ë“œì˜ Private score ê¸°ì¤€ 110000 ì´í•˜ì˜ ì ìˆ˜ë¥¼ ì–»ì—ˆë‹¤.|"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiffel_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
