{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. 다음에 볼 영화 예측하기\n",
    "\n",
    "**고객이 바로 지금 원하는 것이 무엇인지를 예측하여 추천하는 Session-based Recommendation 개념을 익히고 실제로 모델을 구축해 본다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "- Step 1. 데이터의 전처리\n",
    "- Step 2. 미니 배치의 구성\n",
    "- Step 3. 모델 구성\n",
    "- Step 4. 모델 학습\n",
    "- Step 5. 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GRU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('yoochoose/data/') \n",
    "train_path = data_path / 'ratings.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep='::', header=None, usecols=[0, 1, 2, 3], dtype={0: np.int32, 1: np.int32, 2: np.int32}, nrows=nrows)\n",
    "    data.columns = ['UserId', 'ItemId', 'Rating', 'Time']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(train_path, None)\n",
    "data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유저 수, 아이템 수 확인\n",
    "    - 유저 수: 6040\n",
    "    - 아이템 수: 3706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['UserId'].nunique(), data['ItemId'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 데이터의 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 간단히 구성해 본 데이터셋을 꼼꼼히 살펴보면서 항목별 기본 분석, session length, session time, cleaning 등의 작업을 진행합니다.\n",
    "특히, 이 데이터셋에서는 Session이 아닌 UserID 단위로 데이터가 생성되어 있으므로, 이를 Session 단위로 어떻게 해석할지에 주의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 평점 3 이상만 남김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['Rating'], bins=5)\n",
    "plt.yticks(data['Rating'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Rating']>=3]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 세션이 대략 몇 개의 클릭 데이터를 갖는지 확인\n",
    "- 변수\n",
    "    - session_length\n",
    "        - 같은 UserId 를 공유하는 데이터 row 의 개수\n",
    "        - 해당 세션의 사용자가 그 세션 동안 몇 번의 액션을 취했는지(몇 개의 상품정보를 클릭했는지)의 의미\n",
    "    - UserId: 브라우저에서 웹서버로 접속할 때 항상 포함하게 되는 유저 구분자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_length = data.groupby('UserId').size()\n",
    "session_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'각 세션 길이의 중앙값: {session_length.median()}')\n",
    "print(f'각 세션 길이의 평균값: {session_length.mean()}')\n",
    "print(f'각 세션 길이의 최솟값: {session_length.min()}')\n",
    "print(f'긱 세션 길이의 최댓값: {session_length.max()}')\n",
    "print(f'99.9% 세션의 길이: {session_length.quantile(0.999)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 세션 길이 기준 하위 99.9%까지의 분포 누적합 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_count = session_length.groupby(session_length).size()\n",
    "length_percent_cumsum = length_count.cumsum() / length_count.sum()\n",
    "length_percent_cumsum_999 = length_percent_cumsum[length_percent_cumsum < 0.999]\n",
    "\n",
    "length_percent_cumsum_999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.bar(x=length_percent_cumsum_999.index,\n",
    "        height=length_percent_cumsum_999, color='red')\n",
    "plt.xticks(length_percent_cumsum_999.index)\n",
    "plt.yticks(np.arange(0, 1.01, 0.05))\n",
    "plt.title('Cumsum Percentage Until 0.999', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sesstion Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time format 변경 [[참고]](https://cosmosproject.tistory.com/99)\n",
    "    - Unix timestamp 를 날짜로 변경\n",
    "    - Unix timestamp: 1970년 1월 1일(UTC)로부터 몇 초가 흘렀는지 나타내는 수치\n",
    "    - data.Time.dtypes: <m8[ns]\n",
    "    - cf. pd.to_datetime(data.Time, format='%Y-%m-%d %H:%M:%S:%f') 은 에러가 발생함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = data['Time']\n",
    "data.Time = data.Time.map(dt.datetime.fromtimestamp)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time_diff 생성\n",
    "    - 방법1: data['Time_diff'] = (data.Time - data.Time.shift(1)).fillna(pd.Timedelta('0 days 00:00:00'))\n",
    "    - 방법2: data['Time_diff'] = data.Time.diff()).fillna(pd.Timedelta(seconds=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time_diff'] = (data.Time.diff()).fillna(pd.Timedelta(seconds=0))\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SeesionId 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SessionId'] = data['UserId'].map(str) + data['Timestamp'].map(str)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# change_date = []\n",
    "# for time in data['Time']:\n",
    "#     temp = dt.datetime.fromtimestamp(time)\n",
    "#     change_date.append(temp)\n",
    "\n",
    "# data['Time'] = change_date\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest, latest = data['Time'].min(), data['Time'].max()\n",
    "print(oldest) \n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 길이가 1인 세션 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_session을 제거한 다음 unpopular item을 제거하면 다시 길이가 1인 session이 생길 수 있습니다.\n",
    "# 이를 위해 반복문을 통해 지속적으로 제거 합니다.\n",
    "def cleanse_recursive(data: pd.DataFrame, shortest, least_click) -> pd.DataFrame:\n",
    "    while True:\n",
    "        before_len = len(data)\n",
    "        data = cleanse_short_session(data, shortest)\n",
    "        data = cleanse_unpopular_item(data, least_click)\n",
    "        after_len = len(data)\n",
    "        if before_len == after_len:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_short_session(data: pd.DataFrame, shortest):\n",
    "    session_len = data.groupby('UserId').size()\n",
    "    session_use = session_len[session_len >= shortest].index\n",
    "    data = data[data['UserId'].isin(session_use)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_unpopular_item(data: pd.DataFrame, least_click):\n",
    "    item_popular = data.groupby('ItemId').size()\n",
    "    item_use = item_popular[item_popular >= least_click].index\n",
    "    data = data[data['ItemId'].isin(item_use)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleanse_recursive(data, shortest=2, least_click=5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Valid / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(data: pd.DataFrame, n_days: int):\n",
    "    final_time = data['Time'].max()\n",
    "    session_last_time = data.groupby('UserId')['Time'].max()\n",
    "    session_in_train = session_last_time[session_last_time < final_time - dt.timedelta(n_days)].index\n",
    "    session_in_test = session_last_time[session_last_time >= final_time - dt.timedelta(n_days)].index\n",
    "\n",
    "    before_date = data[data['UserId'].isin(session_in_train)]\n",
    "    after_date = data[data['UserId'].isin(session_in_test)]\n",
    "    after_date = after_date[after_date['ItemId'].isin(before_date['ItemId'])]\n",
    "    return before_date, after_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, test = split_by_date(data, n_days=180)\n",
    "tr, val = split_by_date(tr, n_days=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data에 대한 정보를 살펴봅니다.\n",
    "def stats_info(data: pd.DataFrame, status: str):\n",
    "    print(f'* {status} Set Stats Info\\n'\n",
    "          f'\\t Events: {len(data)}\\n'\n",
    "          f'\\t Sessions: {data[\"UserId\"].nunique()}\\n'\n",
    "          f'\\t Items: {data[\"ItemId\"].nunique()}\\n'\n",
    "          f'\\t First Time : {data[\"Time\"].min()}\\n'\n",
    "          f'\\t Last Time : {data[\"Time\"].max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_info(tr, 'train')\n",
    "stats_info(val, 'valid')\n",
    "stats_info(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에 없는 아이템이 val, test기간에 생길 수 있으므로 train data를 기준으로 인덱싱합니다.\n",
    "id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n",
    "\n",
    "def indexing(df, id2idx):\n",
    "    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))  # id2idx에 없는 아이템은 모르는 값(-1) 처리 해줍니다.\n",
    "    return df\n",
    "\n",
    "tr = indexing(tr, id2idx)\n",
    "val = indexing(val, id2idx)\n",
    "test = indexing(test, id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = data_path / 'processed'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tr.to_pickle(save_path / 'train.pkl')\n",
    "val.to_pickle(save_path / 'valid.pkl')\n",
    "test.to_pickle(save_path / 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 미니 배치의 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 코드 내역을 참고하여 데이터셋과 미니 배치를 구성해 봅시다. Session-Parallel Mini-Batch의 개념에 따라, 학습 속도의 저하가 최소화될 수 있도록 구성합니다.\n",
    "단, 위 Step 1에서 Session 단위를 어떻게 정의했느냐에 따라서 Session-Parallel Mini-Batch이 굳이 필요하지 않을 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline - Session-Parallel Mini-Batch 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SessionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.click_offsets = self.get_click_offsets()  # 각 세션이 시작된 인덱스\n",
    "        self.session_idx = np.arange(self.df['UserId'].nunique())  # indexing to UserId\n",
    "\n",
    "    def get_click_offsets(self):\n",
    "        \"\"\"\n",
    "        Return the indexes of the first click of each session IDs,\n",
    "        \"\"\"\n",
    "        offsets = np.zeros(self.df['UserId'].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby('UserId').size().cumsum()\n",
    "        return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = SessionDataset(tr)\n",
    "tr_dataset.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset.click_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset.session_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SessionDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataLoader:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: SessionDataset, batch_size=50):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
    "        Yields:\n",
    "            input (B,):  Item indices that will be encoded as one-hot vectors later.\n",
    "            target (B,): a Variable that stores the target item indices\n",
    "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        start, end, mask, last_session, finished = self.initialize()  # initialize 메소드에서 확인해주세요.\n",
    "        \"\"\"\n",
    "        start : Index Where Session Start\n",
    "        end : Index Where Session End\n",
    "        mask : indicator for the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        while not finished:\n",
    "            min_len = (end - start).min() - 1  # Shortest Length Among Sessions\n",
    "            for i in range(min_len):\n",
    "                # Build inputs & targets\n",
    "                inp = self.dataset.df['item_idx'].values[start + i]\n",
    "                target = self.dataset.df['item_idx'].values[start + i + 1]\n",
    "                yield inp, target, mask\n",
    "\n",
    "            start, end, mask, last_session, finished = self.update_status(start, end, min_len, last_session, finished)\n",
    "\n",
    "    def initialize(self):\n",
    "        first_iters = np.arange(self.batch_size)    # 첫 배치에 사용할 세션 Index를 가져옵니다.\n",
    "        last_session = self.batch_size - 1    # 마지막으로 다루고 있는 세션 Index를 저장해둡니다.\n",
    "        start = self.dataset.click_offsets[self.dataset.session_idx[first_iters]]       # data 상에서 session이 시작된 위치를 가져옵니다.\n",
    "        end = self.dataset.click_offsets[self.dataset.session_idx[first_iters] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n",
    "        mask = np.array([])   # session의 모든 아이템을 다 돌은 경우 mask에 추가해줄 것입니다.\n",
    "        finished = False         # data를 전부 돌았는지 기록하기 위한 변수입니다.\n",
    "        return start, end, mask, last_session, finished\n",
    "\n",
    "    def update_status(self, start: np.ndarray, end: np.ndarray, min_len: int, last_session: int, finished: bool):  \n",
    "        # 다음 배치 데이터를 생성하기 위해 상태를 update합니다.\n",
    "        \n",
    "        start += min_len   # __iter__에서 min_len 만큼 for문을 돌았으므로 start를 min_len 만큼 더해줍니다.\n",
    "        mask = np.arange(self.batch_size)[(end - start) == 1]  \n",
    "        # end는 다음 세션이 시작되는 위치인데 start와 한 칸 차이난다는 것은 session이 끝났다는 뜻입니다. mask에 기록해줍니다.\n",
    "\n",
    "        for i, idx in enumerate(mask, start=1):  # mask에 추가된 세션 개수만큼 새로운 세션을 돌것입니다.\n",
    "            new_session = last_session + i  \n",
    "            if new_session > self.dataset.session_idx[-1]:  # 만약 새로운 세션이 마지막 세션 index보다 크다면 모든 학습데이터를 돈 것입니다.\n",
    "                finished = True\n",
    "                break\n",
    "            # update the next starting/ending point\n",
    "            start[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session]]     # 종료된 세션 대신 새로운 세션의 시작점을 기록합니다.\n",
    "            end[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session] + 1]\n",
    "\n",
    "        last_session += len(mask)  # 마지막 세션의 위치를 기록해둡니다.\n",
    "        return start, end, mask, last_session, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_loader = SessionDataLoader(tr_dataset, batch_size=4)\n",
    "tr_dataset.df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ex = iter(tr_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels, mask =  next(iter_ex)\n",
    "print(f'Model Input Item Idx are : {inputs}')\n",
    "print(f'Label Item Idx are : {\"\":5} {labels}')\n",
    "print(f'Previous Masked Input Idx are {mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 부분도 실습 코드 내역을 참고하여 다양하게 모델 구조를 시도해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args):\n",
    "    inputs = Input(batch_shape=(args.batch_size, 1, args.num_items))\n",
    "    gru, _ = GRU(args.hsz, stateful=True, return_state=True, name='GRU')(inputs)\n",
    "    dropout = Dropout(args.drop_rate)(gru)\n",
    "    predictions = Dense(args.num_items, activation='softmax')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=[predictions])\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyper-parameter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n",
    "        self.tr = tr\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.num_items = tr['ItemId'].nunique()\n",
    "        self.num_sessions = tr['UserId'].nunique()\n",
    "        self.batch_size = batch_size\n",
    "        self.hsz = hsz\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(tr, val, test, batch_size=2048, hsz=50, drop_rate=0.1, lr=0.001, epochs=3, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 하이퍼파라미터를 변경해 보며 검증해 보도록 합니다. 실습 코드에 언급되었던 Recall, MRR 등의 개념들도 함께 관리될 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_k(pred, truth: int, k: int):\n",
    "    indexing = np.where(pred[:k] == truth)[0]\n",
    "    if len(indexing) > 0:\n",
    "        return 1 / (indexing[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def recall_k(pred, truth: int, k: int) -> int:\n",
    "    answer = truth in pred[:k]\n",
    "    return int(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 셋으로 학습하면서 valid 셋으로 검증합니다.\n",
    "def train_model(model, args):\n",
    "    train_dataset = SessionDataset(args.tr)\n",
    "    train_loader = SessionDataLoader(train_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        total_step = len(args.tr) - args.tr['UserId'].nunique()\n",
    "        tr_loader = tqdm(train_loader, total=total_step // args.batch_size, desc='Train', mininterval=1)\n",
    "        for feat, target, mask in tr_loader:\n",
    "            reset_hidden_states(model, mask)  # 종료된 session은 hidden_state를 초기화합니다. 아래 메서드에서 확인해주세요.\n",
    "\n",
    "            input_ohe = to_categorical(feat, num_classes=args.num_items)\n",
    "            input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "            target_ohe = to_categorical(target, num_classes=args.num_items)\n",
    "\n",
    "            result = model.train_on_batch(input_ohe, target_ohe)\n",
    "            tr_loader.set_postfix(train_loss=result[0], accuracy = result[1])\n",
    "\n",
    "        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)  # valid set에 대해 검증합니다.\n",
    "\n",
    "        print(f\"\\t - Recall@{args.k} epoch {epoch}: {val_recall:3f}\")\n",
    "        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:3f}\\n\")\n",
    "\n",
    "\n",
    "def reset_hidden_states(model, mask):\n",
    "    gru_layer = model.get_layer(name='GRU')  # model에서 gru layer를 가져옵니다.\n",
    "    hidden_states = gru_layer.states[0].numpy()  # gru_layer의 parameter를 가져옵니다.\n",
    "    for elt in mask:  # mask된 인덱스 즉, 종료된 세션의 인덱스를 돌면서\n",
    "        hidden_states[elt, :] = 0  # parameter를 초기화 합니다.\n",
    "    gru_layer.reset_states(states=hidden_states)\n",
    "\n",
    "\n",
    "def get_metrics(data, model, args, k: int):  # valid셋과 test셋을 평가하는 코드입니다. \n",
    "                                             # train과 거의 같지만 mrr, recall을 구하는 라인이 있습니다.\n",
    "    dataset = SessionDataset(data)\n",
    "    loader = SessionDataLoader(dataset, batch_size=args.batch_size)\n",
    "    recall_list, mrr_list = [], []\n",
    "\n",
    "    total_step = len(data) - data['UserId'].nunique()\n",
    "    for inputs, label, mask in tqdm(loader, total=total_step // args.batch_size, desc='Evaluation', mininterval=1):\n",
    "        reset_hidden_states(model, mask)\n",
    "        input_ohe = to_categorical(inputs, num_classes=args.num_items)\n",
    "        input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "\n",
    "        pred = model.predict(input_ohe, batch_size=args.batch_size)\n",
    "        pred_arg = tf.argsort(pred, direction='DESCENDING')  # softmax 값이 큰 순서대로 sorting 합니다.\n",
    "\n",
    "        length = len(inputs)\n",
    "        recall_list.extend([recall_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "        mrr_list.extend([mrr_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "\n",
    "    recall, mrr = np.mean(recall_list), np.mean(mrr_list)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시간이 다소 오래 소요됩니다. 아래 주석을 풀지 마세요.\n",
    "# train_model(model, args)\n",
    "\n",
    "# 학습된 모델을 불러옵니다.\n",
    "model = tf.keras.models.load_model(data_path / 'trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미리 구성한 테스트셋을 바탕으로 Recall, MRR 을 확인해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, args, test):\n",
    "    test_recall, test_mrr = get_metrics(test, model, args, 20)\n",
    "    print(f\"\\t - Recall@{args.k}: {test_recall:3f}\")\n",
    "    print(f\"\\t - MRR@{args.k}: {test_mrr:3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, args, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 변경 후 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# GRU4REC Tuning Hyper Parameters\n",
    "learning_rate_choice = [0.01,0.005,0.001,0.0005,0.0001]\n",
    "dropout_prob_choice = [0.0,0.1,0.2,0.3,0.4,0.5]  # The dropout rate. Defaults to 0.3.\n",
    "num_layers_choice = [1,2,3]  # The number of layers in GRU. Defaults to 1.\n",
    "hidden_size_choice = [128]  # The number of features in the hidden state. Defaults to 128.\n",
    "embedding_size_choice = [64]  # The embedding size of items. Defaults to 64\n",
    "loss_type_choice = ['BPR', 'CE']  # Defaults to 'CE'(multi-classification, negative sampling is not needed.)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개선1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(tr, val, test, batch_size=128, hsz=50, drop_rate=0.3, lr=0.1, epochs=3, k=20)\n",
    "train_model(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, args, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 개선2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(tr, val, test, batch_size=64, hsz=128, drop_rate=0.3, lr=0.1, epochs=3, k=20)\n",
    "train_model(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, args, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "### - 이번 프로젝트에서 **어려웠던 점**.\n",
    "SessionId 를 만들어 내는 것이 쉽지 않았다.\n",
    "\n",
    "### - 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**.\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) 라이브러리\n",
    "    - os 모듈 vs pathlib 모듈 [[참고]](https://engineer-mole.tistory.com/191)\n",
    "\n",
    "| **처리내용**                   | **os 및 os.path**    | **pathlib**                             |\n",
    "| ------------------------------ | -------------------- | --------------------------------------- |\n",
    "| 현재의 디렉토리를 취득         | os.getcwd()          | Path.cwd()                              |\n",
    "| 맨 앞의 ~를 홈 디렉토리에 치환 | os.path.expanduser() | Path.expanduser(), Path.home()          |\n",
    "| 경로의 존재 확인               | os.path.exists()     | Path.exists()                           |\n",
    "| 디렉토리인가를 판단            | os.path.isdir()      | Path.is_dir()                           |\n",
    "| 파일인가를 판단                | os.path.isfile()     | Path.is_file()                          |\n",
    "| 심볼릭 링크인가를 판단         | os.path.islink()     | Path.is_symlink()                       |\n",
    "| 절대경로인가를 판단            | os.path.isabs()      | PurePath.is_absolute()                  |\n",
    "| 절대경로로 변환                | os.path.abspath()    | Path.resolve()                          |\n",
    "| status를 취득                  | os.stat()            | Path.stat(), Path.owner(), Path.group() |\n",
    "| 경로를 연결                    | os.path.join()       | PurePath.joinpath()                     |\n",
    "| 파일명을 취득                  | os.path.basename()   | PurePath.name                           |\n",
    "| 새로운 디렉토리를 취득         | os.path.dirname()    | PurePath.parent                         |\n",
    "| 확장자를 분할·취득             | os.path.splitext()   | PurePath.\n",
    "\n",
    "- [GRU(Gated Reccurent Unit)](https://yjjo.tistory.com/18) [[참고1]](https://hyen4110.tistory.com/26) [[참고2]](https://wooono.tistory.com/242) [참고3](https://blog.naver.com/winddori2002/221992543837)\n",
    "    - GRU 등장\n",
    "        - LSTM(Long Short Term Memory)\n",
    "            - RNN 의 치명적 한계점인 Long-term dependency 문제 해결\n",
    "            - RNN 보다 파라미터 많아짐 => 데이터가 충분하지 않은 경우 오버피팅 발생\n",
    "            - hidden state, cell state\n",
    "            - Forget gate, Input gate, Output gate\n",
    "        - LSTM을 구성하는 Time-Step의 Cell을 조금 더 간소화한 버전\n",
    "        - ![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb6kVlm%2Fbtq4Cs5VOPX%2Fr73EUarFNRgaDGdJ7r1Hvk%2Fimg.png)\n",
    "    - 데이터 양이 적을 때는, 매개 변수의 양이 적은 GRU가 조금 더 낫고, 데이터 양이 더 많으면 LSTM이 더 낫다고 알려짐\n",
    "    - GRU는 LSTM과 다르게 Gate가 2개이며, Reset Gate(r)과 Update Gate(z)로 이루어져있다.\n",
    "        - Reset Gate: short-term dependency\n",
    "            - 이전 상태를 얼마나 반영/잊어야 하는지 결정\n",
    "            - 이전 상태 hidden state 와 현재 상태 x 를 받아서 sigmoid 처리\n",
    "            - GRU의 Hidden State = LSTM의 Cell State + Hidden State\n",
    "        - Update Gate: long-term dependency\n",
    "            - 과거(1-z)와 현재(z) 정보(상태)를 각각 얼마만큼의 비율로 반영(유지)할지 결정\n",
    "            - Update Gate = LSTM의 forget gate + input gate 역할\n",
    "            - 최종 결과는 다음 상태의 hidden state 로 보내짐\n",
    "    - Output Gate 없음\n",
    "\n",
    "| **LSTM**                                            | **GRU**                                                    |\n",
    "| --------------------------------------------------- | ---------------------------------------------------------- |\n",
    "| gate 수 3개(forget, input, output)                  | gate 수 2개(reset, update)                                 |\n",
    "| Control the exposure of memory content (cell state) | Expose the entire cell state to other units in the network |\n",
    "| Has separate input and forget gates                 | Performs both of these operations together via update gate |\n",
    "| More parameters                                     | Fewer parameters     \n",
    "\n",
    "- [GRU4REC](https://arxiv.org/pdf/1511.06939v4.pdf) [[참고1]](https://recbole.io/docs/user_guide/model/sequential/gru4rec.html)\n",
    "    - ![](https://recbole.io/docs/_images/gru4rec.png)\n",
    "    - Session Data에서는 처음으로 RNN 계열 모델을 적용하여 발표\n",
    "    - 여러 RNN 계열 모델 중에서 GRU 성능이 가장 좋았음\n",
    "    - Embedding Layer 사용하지 않았을 때 성능이 더 좋았음 => One-hot Encoding 만 사용\n",
    "    - Session-Parallel Mini-Batches\n",
    "        - Session이 끝날 때까지 기다리지 않고 병렬적으로 계산\n",
    "    - 공식 깃허브: [hidasib/GRU4Rec](https://github.com/hidasib/GRU4Rec)\n",
    "    - Tuning Hyper Parameters\n",
    "\n",
    "```python\n",
    "# GRU4REC Tuning Hyper Parameters\n",
    "learning_rate_choice = [0.01,0.005,0.001,0.0005,0.0001]\n",
    "dropout_prob_choice = [0.0,0.1,0.2,0.3,0.4,0.5]  # The dropout rate. Defaults to 0.3.\n",
    "num_layers_choice = [1,2,3]  # The number of layers in GRU. Defaults to 1.\n",
    "hidden_size_choice = [128]  # The number of features in the hidden state. Defaults to 128.\n",
    "embedding_size_choice = [64]  # The embedding size of items. Defaults to 64\n",
    "loss_type_choice = ['BPR', 'CE']  # Defaults to 'CE'(multi-classification, negative sampling is not needed.)\n",
    "```\n",
    "\n",
    "- Evaluation Metrics [[참고1]](https://zzaebok.github.io/recommender_system/metrics/rec_metrics/) [[참고2]](https://danthetech.netlify.app/DataScience/evaluation-metrics-for-recommendation-system)\n",
    "    - Metrics\n",
    "        - 특징\n",
    "            - test set의 전체 데이터를 대상으로 성능을 측정\n",
    "        - 종류\n",
    "            - Accracy\n",
    "                - 정확도\n",
    "                - 전체 test set에서 긍정과 부정을 포함하여 몇개를 맞았는가\n",
    "            - Precision\n",
    "                - 정밀도\n",
    "                - 모델이 실제로 Positive로 예측한 것 중 실제 Positive인 것의 비율\n",
    "            - Recall\n",
    "                - 재현율\n",
    "                - 실제 True인 것중에 모델이 True라고 예측한 것의 비율\n",
    "            - F1\n",
    "                - precision score와 recall score의 조화평균\n",
    "            - AUC\n",
    "                - ROC curve 의 면적을 구한 값\n",
    "                - ROC curve: True positive rate과 1-True negative rate의 비율을 그래프로 그린 것\n",
    "    - Rank-less Recommendation Metrics\n",
    "        - 특징\n",
    "            - 단순히 ‘맞았냐 안맞았냐’를 측정(accuracy)하기보단 ‘맞추되 얼마나 상위에 위치시킬 수 있는가?’가 매우 중요\n",
    "            - precision, recall은 추천 task에서 precision@k, recall@k라는 변형된 모습으로 사용\n",
    "            - k개의 추천에 대한 평가지표로서 사용\n",
    "            - 단점: rank에 따른 상대적인 선호도를 제대로 반영하지 못함\n",
    "        - 종류\n",
    "            - Precision@k\n",
    "                - k개의 추천 중 실제로 사용자가 선호하는 (relevant) 아이템이 얼마나 존재하는지를 측정\n",
    "                - Precision: 사용자에게 useful한 item을 얼마나 잘 추천해주었는가\n",
    "            - Recall@k\n",
    "                - 전체 relevant한 아이템 중 추천된 아이템이 속한 비율 => K 개 추천했을때, 추천되어야했을 relevant item이 몇 개 추천되어져 있느냐\n",
    "                - Recall: useful stuff에 대한 추천을 최대한 놓치지 않는 것\n",
    "            - Hit@k: k개의 추천 중에 relevant한 것이 있으면 1 아니면 0\n",
    "    - Rank-aware Recommendation Metrics\n",
    "        - 특징\n",
    "            - Ranked 검색 결과를 평가\n",
    "            - 추천된 상대적인 위치에 따라서 점수를 차등하여 부여\n",
    "        - 종류\n",
    "            - MAP(Mean Average Precision)\n",
    "                - 전체 사용자에 대해서 평가(=Average precision을 구해서 평균냄)하는 것\n",
    "                - Average Precision\n",
    "                    - 한명의 사용자에게 추천한 결과를 평가한 것\n",
    "                    - precision@k에서 k를 점점 늘려가며 얻게되는 precision score를 평균낸 것\n",
    "                - Precision은 틀린 예측을 하게 되면 그 값이 떨어지지만, Recall에는 변화가 없다.(분모는 실제로 positive인 개수이므로 변화가 없다)\n",
    "                - 장점: 여러 가지 relevant한 아이템들을 추천 내에서 상대적인 score로 반영할 수 있다.\n",
    "                - 단점: 1~5점으로 star를 매기는 rating과 같은 경우에는 적용할 수 없다. => binary rating (1/0)에 최적화\n",
    "            - MRR(Mean Reciprocal Rank)\n",
    "                - Reciprocal rank: 첫 번째로 등장하는 relevant한 아이템이 우리의 추천상 몇 번째에 위치하는지를 나타내는 지표\n",
    "                - 정답 아이템이 나온 순번의 역수 값\n",
    "                - 정답 아이템이 추천 결과 앞쪽 순번에 나온다면 지표가 높아질 것이고 뒤쪽에 나오거나 안 나온다면 지표가 낮아질 것\n",
    "                - 단점: 추천 상의 몇 개의 relevant아이템이 나오든 첫 번째로 나오는 relevant 아이템만 신경쓴다.\n",
    "            - nDCG(normalized Discounted Cumulative Gain)\n",
    "                - CG(Cumulative Gain): relevance score를 더하는 것\n",
    "                - Discount 개념: relevance score를 등장 위치에 따라 조정하는 것\n",
    "                - normalize (0~1) 으로 k개의 추천 개수가 커지면 커질수록 점수가 높아지는 단점 해결\n",
    "\n",
    "\n",
    "### - 루브릭 평가 지표를 맞추기 위해 **시도한 것들**.\n",
    "\n",
    ">#### **루브릭**\n",
    ">|번호|평가문항|상세기준|\n",
    ">|:---:|---|---|\n",
    ">|1|Movielens 데이터셋을 session based recommendation 관점으로 전처리하는 과정이 체계적으로 진행되었다.|데이터셋의 면밀한 분석을 토대로 세션단위 정의 과정(길이분석, 시간분석)을 합리적으로 수행한 과정이 기술되었다.|\n",
    ">|2|RNN 기반의 예측 모델이 정상적으로 구성되어 안정적으로 훈련이 진행되었다.|적절한 epoch만큼의 학습이 진행되는 과정에서 train loss가 안정적으로 감소하고, validation 단계에서의 Recall, MRR이 개선되는 것이 확인된다.|\n",
    ">|3|세션정의, 모델구조, 하이퍼파라미터 등을 변경해서 실험하여 Recall, MRR 등의 변화추이를 관찰하였다.|3가지 이상의 변화를 시도하고 그 실험결과를 체계적으로 분석하였다.|\n",
    "\n",
    "UserId 와 Time 컬럼으로 SessionId 를 만들어서 세션 단위 분석을 진행했다. 모델링하고 학습시켜서 Recall 과 MRR 이 개선되었음을 확인했다. Recall 과 MRR 의 변화를 살펴보았다.\n",
    "\n",
    "\n",
    "### - 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**.\n",
    "없음\n",
    "\n",
    "### - **자기 다짐**\n",
    "다른 추천 시스템 구현 방법도 찾아보면 좋겠다는 생각이 들었다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiffel_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
