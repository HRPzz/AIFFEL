# 4. 작사가 인공지능 만들기
**LSTM 모델과 셰익스피어 데이터셋을 사용해 간단한 작사가 인공지능을 만들어 본다.**

- 시퀀스(Sequence) 데이터: 나열된 데이터를 의미
- 많은 데이터가 곧 좋은 결과를 만듦
- 순환신경망(RNN)
  - 생성한 단어를 다시 입력으로 사용
  - 언어 모델(Language Model): n번째 단어 $w_n$으로 무엇이 올지를 예측하는 확률 모델

---
## 목차
- 시퀀스? 스퀀스!
- I 다음 am을 쓰면 반 이상은 맞더라
- 실습
  - 1) 데이터 다듬기
  - 2) 인공지능 학습시키기
  - 3) 잘 만들어졌는지 평가하기
- 프로젝트 : 멋진 인공지능 작사가 만들기

---
## 4-7. 프로젝트: 멋진 작사가 만들기
- Step 1. 데이터 다운로드
- Step 2. 데이터 읽어오기
  - glob 모듈 사용하여 파일 읽기
- Step 3. 데이터 정제
  - 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거
  - => 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기
- Step 4. 평가 데이터셋 분리
  - 훈련 데이터와 평가 데이터를 분리
  - 단어장의 크기는 12,000 이상, 총 데이터의 20% 를 평가 데이터셋으로 사용
- Step 5. 인공지능 만들기
  - 모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계! (Loss는 아래 제시된 Loss 함수를 그대로 사용!)

---
>## **루브릭**
>|번호|평가문항|상세기준|평가결과|
>|:---:|---|---|:---:|
>|1|가사 텍스트 생성 모델이 정상적으로 동작하는가?|텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?|★|
>|2|데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?|특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?|★|
>|3|텍스트 생성모델이 안정적으로 학습되었는가?|텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?|☆|
