# 12. 트랜스포머로 만드는 대화형 챗봇
**트랜스포머의 인코더 디코더 구조와 셀프 어텐션을 코드를 통해 이해해 본다. 이를 영어와 한국어로 이루어진 챗봇 데이터에 적용해 본다.**

- 챗봇 대표적 5가지 유형
    - 대화형 챗봇
    - 트리형(버튼) 챗봇
    - 추천형 챗봇
    - 시나리오형 챗봇
    - 결합형 챗봇
    - => 대화형 제외하면 사실상 챗봇은 대화형 UX를 가졌지만 본질적으로는 검색엔진이거나, 혹은 음성 ARS를 대화형 UX에 옮겨놓은 것

- 트랜스포머(Transformer) 모델을 기반으로 한 인코더-디코더 구조를 바탕으로 챗봇을 제작할 예정
    - 트랜스포머
        - 병렬처리에 불리한 LSTM에 비해 뛰어난 처리 속도
        - LSTM, RNN 모델 단점인 장기 의존성에 강건함 => 매우 긴 길이의 문장 처리에 유리함
        - => 자연어처리 분야의 혁신을 가져옴
    - 인코더-디코더 구조: seq2seq, AutoEncoder, GAN 등
        - e.g. seq2seq 모델 기반 번역기(영어->한국어)
            - 영어 문장->(인코더)->벡터->(디코더)->한국어 문장 생성
    - 더 좋은 성능을 원한다면 엄청나게 많은 corpus로 학습시킨 pretrained model 활용

---
### 학습 목표
- 트랜스포머의 인코더 디코더 구조 이해하기
- 내부 단어 토크나이저 사용하기
- 셀프 어텐션 이해하기
- 한국어에도 적용해보기

---
## 12-14. 프로젝트: 한국어 데이터로 챗봇 만들기
영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련

- Step 1. 데이터 수집하기
    - 송영숙님이 공개한 한국어 챗봇 데이터: [songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)
- Step 2. 데이터 전처리하기
- Step 3. SubwordTextEncoder 사용하기
- Step 4. 모델 구성하기
- Step 5. 모델 평가하기

---
>## **루브릭**
>|번호|평가문항|상세기준|평가결과|
>|:---:|---|---|:---:|
>|1|한국어 전처리를 통해 학습 데이터셋을 구축하였다.|공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.|-|
>|2|트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.|구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|-|
>|3|한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.|한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.|-|

