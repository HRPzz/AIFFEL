{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23. 딥러닝 레이어의 이해(1) Linear, Convolution\n",
    "\n",
    "**딥러닝에서 레이어의 개념을 이해하고, 그 중 Linear 레이어와 Convolution 레이어에 대해 보다 자세하게 알아본다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-1. 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-2. 데이터의 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-3. 레이어는 어렵다?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-4. 딥러닝의 근본! Linear 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "boxes = tf.zeros((batch_size, 4, 2))     # Tensorflow는 Batch를 기반으로 동작하기에,\n",
    "                                         # 우리는 사각형 2개 세트를 batch_size개만큼\n",
    "                                         # 만든 후 처리를 하게 됩니다.\n",
    "print(\"1단계 연산 준비:\", boxes.shape)\n",
    "\n",
    "first_linear = tf.keras.layers.Dense(units=1, use_bias=False) \n",
    "# units은 출력 차원 수를 의미합니다.\n",
    "# Weight 행렬 속 실수를 인간의 뇌 속 하나의 뉴런 '유닛' 취급을 하는 거죠!\n",
    "\n",
    "first_out = first_linear(boxes)\n",
    "first_out = tf.squeeze(first_out, axis=-1) # (4, 1)을 (4,)로 변환해줍니다.\n",
    "                                           # (불필요한 차원 축소)\n",
    "\n",
    "print(\"1단계 연산 결과:\", first_out.shape)\n",
    "print(\"1단계 Linear Layer의 Weight 형태:\", first_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n2단계 연산 준비:\", first_out.shape)\n",
    "\n",
    "second_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "second_out = second_linear(first_out)\n",
    "second_out = tf.squeeze(second_out, axis=-1)\n",
    "\n",
    "print(\"2단계 연산 결과:\", second_out.shape)\n",
    "print(\"2단계 Linear Layer의 Weight 형태:\", second_linear.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "boxes = tf.zeros((batch_size, 4, 2))\n",
    "\n",
    "print(\"1단계 연산 준비:\", boxes.shape)\n",
    "\n",
    "########\n",
    "# Step 1: (4,2)차원인 boxes를 (4,3)으로 확장시키는 Linear Layer를 활용하세요.\n",
    "# Enter Your Source\n",
    "first_linear = tf.keras.layers.Dense(units=3, use_bias=False)\n",
    "first_out = first_linear(boxes)\n",
    "\n",
    "\n",
    "########\n",
    "\n",
    "print(\"1단계 연산 결과:\", first_out.shape)\n",
    "print(\"1단계 Linear Layer의 Weight 형태:\", first_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n2단계 연산 준비:\", first_out.shape)\n",
    "\n",
    "# Dense = Linear\n",
    "second_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "second_out = second_linear(first_out)\n",
    "second_out = tf.squeeze(second_out, axis=-1)\n",
    "\n",
    "print(\"2단계 연산 결과:\", second_out.shape)\n",
    "print(\"2단계 Linear Layer의 Weight 형태:\", second_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n3단계 연산 준비:\", second_out.shape)\n",
    "\n",
    "########\n",
    "# Step 2: 4차원인 second_out을 하나의 실수으로 집약시키는 Linear Layer를 활용하세요.\n",
    "# Enter Your Source\n",
    "third_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "third_out = third_linear(second_out)\n",
    "third_out = tf.squeeze(third_out, axis=-1)\n",
    "\n",
    "########\n",
    "\n",
    "print(\"3단계 연산 결과:\", third_out.shape)\n",
    "print(\"3단계 Linear Layer의 Weight 형태:\", third_linear.weights[0].shape)\n",
    "\n",
    "########\n",
    "# Step 3: 모든 params를 더하여 total_parmams를 구하세요.\n",
    "# Enter Your Source\n",
    "total_params = first_linear.count_params() + \\\n",
    "\t\t\t\tsecond_linear.count_params() + \\\n",
    "\t\t\t\tthird_linear.count_params()\n",
    "\n",
    "\n",
    "########\n",
    "\n",
    "print(\"총 Parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 정답 코드\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "boxes = tf.zeros((batch_size, 4, 2))\n",
    "\n",
    "print(\"1단계 연산 준비:\", boxes.shape)\n",
    "\n",
    "first_linear = tf.keras.layers.Dense(units=3, use_bias=False)\n",
    "first_out = first_linear(boxes)\n",
    "\n",
    "print(\"1단계 연산 결과:\", first_out.shape)\n",
    "print(\"1단계 Linear Layer의 Weight 형태:\", first_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n2단계 연산 준비:\", first_out.shape)\n",
    "\n",
    "second_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "second_out = second_linear(first_out)\n",
    "second_out = tf.squeeze(second_out, axis=-1)\n",
    "\n",
    "print(\"2단계 연산 결과:\", second_out.shape)\n",
    "print(\"2단계 Linear Layer의 Weight 형태:\", second_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n3단계 연산 준비:\", second_out.shape)\n",
    "\n",
    "third_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "third_out = third_linear(second_out)\n",
    "third_out = tf.squeeze(third_out, axis=-1)\n",
    "\n",
    "print(\"3단계 연산 결과:\", third_out.shape)\n",
    "print(\"3단계 Linear Layer의 Weight 형태:\", third_linear.weights[0].shape)\n",
    "\n",
    "total_params = \\\n",
    "first_linear.count_params() + \\\n",
    "second_linear.count_params() + \\\n",
    "third_linear.count_params()\n",
    "\n",
    "print(\"총 Parameters:\", total_params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-5. 정보를 집약시키자! Convolution 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "pic = tf.zeros((batch_size, 1920, 1080, 3))\n",
    "\n",
    "print(\"입력 이미지 데이터:\", pic.shape)\n",
    "conv_layer = tf.keras.layers.Conv2D(filters=16,\n",
    "                                    kernel_size=(5, 5),\n",
    "                                    strides=5,\n",
    "                                    use_bias=False)\n",
    "conv_out = conv_layer(pic)\n",
    "\n",
    "print(\"\\nConvolution 결과:\", conv_out.shape)\n",
    "print(\"Convolution Layer의 Parameter 수:\", conv_layer.count_params())\n",
    "\n",
    "flatten_out = tf.keras.layers.Flatten()(conv_out)\n",
    "print(\"\\n1차원으로 펼친 데이터:\", flatten_out.shape)\n",
    "\n",
    "linear_layer = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "linear_out = linear_layer(flatten_out)\n",
    "\n",
    "print(\"\\nLinear 결과:\", linear_out.shape)\n",
    "print(\"Linear Layer의 Parameter 수:\", linear_layer.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-6. 핵심만 추려서 더 넓게! Pooling 레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-7. 집약된 정보의 복원! Deconvolution 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import json\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "\n",
    "# MNIST 데이터 로딩\n",
    "(x_train, _), (x_test, _) = mnist.load_data()    # y_train, y_test는 사용하지 않습니다.\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoder 모델 구성 - Input 부분\n",
    "input_shape = x_train.shape[1:]\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "# AutoEncoder 모델 구성 - Encoder 부분\n",
    "encode_conv_layer_1 = Conv2D(16, (3, 3), activation='relu', padding='same')\n",
    "encode_pool_layer_1 = MaxPooling2D((2, 2), padding='same')\n",
    "encode_conv_layer_2 = Conv2D(8, (3, 3), activation='relu', padding='same')\n",
    "encode_pool_layer_2 = MaxPooling2D((2, 2), padding='same')\n",
    "encode_conv_layer_3 = Conv2D(4, (3, 3), activation='relu', padding='same')\n",
    "encode_pool_layer_3 = MaxPooling2D((2, 2), padding='same')\n",
    "\n",
    "encoded = encode_conv_layer_1(input_img)\n",
    "encoded = encode_pool_layer_1(encoded)\n",
    "encoded = encode_conv_layer_2(encoded)\n",
    "encoded = encode_pool_layer_2(encoded)\n",
    "encoded = encode_conv_layer_3(encoded)\n",
    "encoded = encode_pool_layer_3(encoded)\n",
    "\n",
    "# AutoEncoder 모델 구성 - Decoder 부분\n",
    "decode_conv_layer_1 = Conv2D(4, (3, 3), activation='relu', padding='same')\n",
    "decode_upsample_layer_1 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_2 = Conv2D(8, (3, 3), activation='relu', padding='same')\n",
    "decode_upsample_layer_2 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_3 = Conv2D(16, (3, 3), activation='relu')\n",
    "decode_upsample_layer_3 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_4 = Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "\n",
    "decoded = decode_conv_layer_1(encoded)   # Decoder는 Encoder의 출력을 입력으로 받습니다.\n",
    "decoded = decode_upsample_layer_1(decoded)\n",
    "decoded = decode_conv_layer_2(decoded)\n",
    "decoded = decode_upsample_layer_2(decoded)\n",
    "decoded = decode_conv_layer_3(decoded)\n",
    "decoded = decode_upsample_layer_3(decoded)\n",
    "decoded = decode_conv_layer_4(decoded)\n",
    "\n",
    "# AutoEncoder 모델 정의\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_10 = x_test[:10]       # 테스트 데이터셋에서 10개만 골라서\n",
    "x_test_hat = autoencoder.predict(x_test_10)    # AutoEncoder 모델의 이미지 복원생성\n",
    "x_test_imgs = x_test_10.reshape(-1, 28, 28)\n",
    "x_test_hat_imgs = x_test_hat.reshape(-1, 28, 28)\n",
    "\n",
    "plt.figure(figsize=(12,5))  # 이미지 사이즈 지정\n",
    "for i in range(10):  \n",
    "    # 원본이미지 출력\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(x_test_imgs[i])\n",
    "    # 생성된 이미지 출력\n",
    "    plt.subplot(2, 10, i+11)\n",
    "    plt.imshow(x_test_hat_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "\n",
    "# Conv2DTranspose를 활용한  AutoEncoder 모델\n",
    "# AutoEncoder 모델 구성 - Input 부분\n",
    "input_shape = x_train.shape[1:]\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "# AutoEncoder 모델 구성 - Encoder 부분\n",
    "encode_conv_layer_1 = Conv2D(16, (3, 3), activation='relu')\n",
    "encode_pool_layer_1 = MaxPooling2D((2, 2))\n",
    "encode_conv_layer_2 = Conv2D(8, (3, 3), activation='relu')\n",
    "encode_pool_layer_2 = MaxPooling2D((2, 2))\n",
    "encode_conv_layer_3 = Conv2D(4, (3, 3), activation='relu')\n",
    "\n",
    "encoded = encode_conv_layer_1(input_img)\n",
    "encoded = encode_pool_layer_1(encoded)\n",
    "encoded = encode_conv_layer_2(encoded)\n",
    "encoded = encode_pool_layer_2(encoded)\n",
    "encoded = encode_conv_layer_3(encoded)\n",
    "\n",
    "# AutoEncoder 모델 구성 - Decoder 부분  - \n",
    "decode_conv_layer_1 = Conv2DTranspose(4, (3, 3), activation='relu', padding='same')\n",
    "decode_upsample_layer_1 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_2 = Conv2DTranspose(8, (3, 3), activation='relu', padding='same')\n",
    "decode_upsample_layer_2 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_3 = Conv2DTranspose(16, (3, 3), activation='relu')\n",
    "decode_upsample_layer_3 = UpSampling2D((2, 2))\n",
    "decode_conv_layer_4 = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')\n",
    "\n",
    "decoded = decode_conv_layer_1(encoded)   # Decoder는 Encoder의 출력을 입력으로 받습니다.\n",
    "decoded = decode_upsample_layer_1(decoded)\n",
    "decoded = decode_conv_layer_2(decoded)\n",
    "decoded = decode_upsample_layer_2(decoded)\n",
    "decoded = decode_conv_layer_3(decoded)\n",
    "decoded = decode_upsample_layer_3(decoded)\n",
    "decoded = decode_conv_layer_4(decoded)\n",
    "\n",
    "# AutoEncoder 모델 정의\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiffel_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
