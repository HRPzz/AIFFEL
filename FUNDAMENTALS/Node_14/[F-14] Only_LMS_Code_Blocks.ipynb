{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. ê±°ìš¸ì•„ ê±°ìš¸ì•„, ë‚˜ëŠ” ë©ë©ì´ ìƒì´ë‹ˆ, ì•„ë‹ˆë©´ ëƒ¥ì´ ìƒì´ë‹ˆ?\n",
    "\n",
    "**ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° ëª¨ë¸ì„ ì‘ìš©í•˜ì—¬ ê°œì™€ ê³ ì–‘ì´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³¸ë‹¤. ì´ë¥¼ ì‘ìš©í•˜ì—¬ ì‚¬ëŒì´ ê°œì™€ ê³ ì–‘ì´ ì¤‘ ì–´ëŠìª½ì„ ë” ë‹®ì•˜ëŠ”ì§€ ì•Œì•„ë³´ëŠ” ì¬ë¯¸ìˆëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬í˜„í•´ ë³¸ë‹¤.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-1. ğŸ¶ ê±°ìš¸ì•„ ê±°ìš¸ì•„, ë‚˜ëŠ” ë©ë©ì´ ìƒì´ë‹ˆ, ì•„ë‹ˆë©´ ëƒ¥ì´ ìƒì´ë‹ˆ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pip install pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-2. ë‚´ê°€ ì§ì ‘ ë§Œë“œëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (1) ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-3. ë‚´ê°€ ì§ì ‘ ë§Œë“œëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (2) ëª¨ë¸ì´ í•™ìŠµí•˜ë ¤ë©´? ê³µë¶€í•  ë°ì´í„°ë¥¼ ì¤˜ì•¼ì§€!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "print(raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-4. ë‚´ê°€ ì§ì ‘ ë§Œë“œëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (3) ë°ì´í„°ê°€ ìˆë‹¤ê³  ëì€ ì•„ë‹ˆì•¼, ì´ì˜ê²Œ ë‹¤ë“¬ëŠ” ì‘ì—…ì€ í•„ìˆ˜!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for idx, (image, label) in enumerate(raw_train.take(10)):  # 10ê°œì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ ì˜µë‹ˆë‹¤.\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'label {label}: {get_label_name(label)}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160 # ë¦¬ì‚¬ì´ì§•í•  ì´ë¯¸ì§€ì˜ í¬ê¸°\n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)  # image=float(image)ê°™ì€ íƒ€ì…ìºìŠ¤íŒ…ì˜  í…ì„œí”Œë¡œìš° ë²„ì „ì…ë‹ˆë‹¤.\n",
    "    image = (image/127.5) - 1 # í”½ì…€ê°’ì˜ scale ìˆ˜ì •\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "\n",
    "print(train)\n",
    "print(validation)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for idx, (image, label) in enumerate(train.take(10)):\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'label {label}: {get_label_name(label)}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-5. ë‚´ê°€ ì§ì ‘ ë§Œë“œëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (4) ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìœ¼ë‹ˆ, ì´ì œ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(160, 160, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.array([[1, 2], [3, 4]])\n",
    "print(image.shape)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-6. ë‚´ê°€ ì§ì ‘ ë§Œë“œëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (5) ëª¨ë¸ì•„ ëª¨ë¸ì•„, ë°ì´í„°ë¥¼ ë¨¹ê³  ë˜‘ë˜‘í•´ì§€ë ´!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "    break\n",
    "\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps = 20\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps=validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-7. ë‚´ê°€ ì§ì ‘ ë§Œë“œëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (6) ëª¨ë¸ì€ ì–¼ë§ˆë‚˜ ë˜‘ë˜‘í•´ì¡Œì„ê¹Œ? í™•ì¸í•´ ë³´ì!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in test_batches.take(1):\n",
    "    images = image_batch\n",
    "    labels = label_batch\n",
    "    predictions = model.predict(image_batch)\n",
    "    break\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "    plt.subplot(4, 8, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    correct = label == prediction\n",
    "    title = f'real: {label} / pred :{prediction}\\n {correct}!'\n",
    "    if not correct:\n",
    "        plt.title(title, fontdict={'color': 'red'})\n",
    "    else:\n",
    "        plt.title(title, fontdict={'color': 'blue'})\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0   # ì •ë‹µì„ ë§ì¶˜ ê°œìˆ˜\n",
    "for image, label, prediction in zip(images, labels, predictions):\n",
    "    # [[YOUR CODE]]\n",
    "    correct = label == prediction  # ì •ë‹µ == ì˜ˆì¸¡\n",
    "    if correct:\n",
    "        count += 1\n",
    "\n",
    "print(count / 32 * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-8. ë‚´ê°€ ì§ì ‘ ë§Œë“¤ì§€ ì•Šê³  ê°€ì ¸ë‹¤ ì“°ëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (1) ì–´ë ¤ìš´ ë¬¸ì œëŠ” ì§ì ‘ í’€ì§€ ë§ì, ë˜‘ë˜‘í•œ ëˆ„êµ°ê°€ê°€ ì´ë¯¸ í’€ì–´ë†¨ì„ í…Œë‹ˆ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-9. ë‚´ê°€ ì§ì ‘ ë§Œë“¤ì§€ ì•Šê³  ê°€ì ¸ë‹¤ ì“°ëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (2) ì•„ì£¼ ë˜‘ë˜‘í•œ ëª¨ë¸ì„ ê°„ë‹¨íˆ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model VGG16\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                         include_top=False,\n",
    "                                         weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch = base_model(image_batch)\n",
    "feature_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-10. ë‚´ê°€ ì§ì ‘ ë§Œë“¤ì§€ ì•Šê³  ê°€ì ¸ë‹¤ ì“°ëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (3) ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ, ë‚´ ì…ë§›ëŒ€ë¡œ ì¬êµ¬ì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.array([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "flattened_image = image.flatten()\n",
    "\n",
    "print(\"Original image:\\n\", image)\n",
    "print(\"Original image shape:\", image.shape)\n",
    "print()\n",
    "print(\"Flattened image:\\n\", flattened_image)\n",
    "print(\"Flattened image shape:\", flattened_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(512, activation='relu')\n",
    "prediction_layer = tf.keras.layers.Dense(2, activation='softmax')\n",
    "\n",
    "# feature_batch_averagê°€ dense_layerë¥¼ ê±°ì¹œ ê²°ê³¼ê°€ ë‹¤ì‹œ prediction_layerë¥¼ ê±°ì¹˜ê²Œ ë˜ë©´\n",
    "prediction_batch = prediction_layer(dense_layer(feature_batch_average))  \n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  dense_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "print(\"ìŠ~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-11. ë‚´ê°€ ì§ì ‘ ë§Œë“¤ì§€ ì•Šê³  ê°€ì ¸ë‹¤ ì“°ëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (4) ê±°ì¸ì˜ ì–´ê¹¨ì— ì˜¬ë¼íƒ€ì„œ ì˜ˆì¸¡í•˜ë‹ˆ, ë” ì˜ ì˜ˆì¸¡í•  ìˆ˜ë°–ì—!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps=20\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5   # ì´ë²ˆì—ëŠ” ì´ì „ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê²Œ ìˆ˜ë ´ë˜ë¯€ë¡œ 5Epochì´ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤.\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in test_batches.take(1):\n",
    "    images = image_batch\n",
    "    labels = label_batch\n",
    "    predictions = model.predict(image_batch)\n",
    "    pass\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "    plt.subplot(4, 8, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    correct = label == prediction\n",
    "    title = f'real: {label} / pred :{prediction}\\n {correct}!'\n",
    "    if not correct:\n",
    "        plt.title(title, fontdict={'color': 'red'})\n",
    "    else:\n",
    "        plt.title(title, fontdict={'color': 'blue'})\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for image, label, prediction in zip(images, labels, predictions):\n",
    "    correct = label == prediction\n",
    "    if correct:\n",
    "        count = count + 1\n",
    "\n",
    "print(count / 32 * 100) # ì•½ 95% ë‚´ì™¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-12. ë‚´ê°€ ì§ì ‘ ë§Œë“¤ì§€ ì•Šê³  ê°€ì ¸ë‹¤ ì“°ëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (5) ì˜ í•™ìŠµëœ ëª¨ë¸ì€ ì €ì¥í•´ë‘ê³ , ì–¸ì œë“  êº¼ë‚´ ì“°ë„ë¡ í•˜ì!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mkdir -p ~/aiffel/cat_vs_dog\n",
    "$ mkdir -p ~/aiffel/cat_vs_dog/checkpoint\n",
    "$ mkdir -p ~/aiffel/cat_vs_dog/images\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = os.getenv(\"HOME\") + \"/aiffel/cat_vs_dog/checkpoint\"\n",
    "checkpoint_file_path = os.path.join(checkpoint_dir, 'checkpoint')\n",
    "\n",
    "if not os.path.exists('checkpoint_dir'):\n",
    "    os.mkdir('checkpoint_dir')\n",
    "    \n",
    "model.save_weights(checkpoint_file_path)     # checkpoint íŒŒì¼ ìƒì„±\n",
    "\n",
    "if os.path.exists(checkpoint_file_path):\n",
    "  print('checkpoint íŒŒì¼ ìƒì„± OK!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-13. ë‚´ê°€ ì§ì ‘ ë§Œë“¤ì§€ ì•Šê³  ê°€ì ¸ë‹¤ ì“°ëŠ” ê°•ì•„ì§€ ê³ ì–‘ì´ ë¶„ë¥˜ê¸° (6) ê±°ìš¸ì•„ ê±°ìš¸ì•„, ë‚˜ëŠ” ë©ë©ì´ ìƒì´ë‹ˆ, ì•„ë‹ˆë©´ ëƒ¥ì´ ìƒì´ë‹ˆ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir_path = os.getenv(\"HOME\") + \"/aiffel/cat_vs_dog/images\"\n",
    "os.path.exists(img_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160\n",
    "dog_image_path = os.path.join(img_dir_path, 'my_dog.jpeg')\n",
    "\n",
    "dog_image = load_img(dog_image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "dog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_image = img_to_array(dog_image).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "dog_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(dog_image)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_and_predict_image(dirpath, filename, img_size=160):\n",
    "    filepath = os.path.join(dirpath, filename)\n",
    "    image = load_img(filepath, target_size=(img_size, img_size))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    image = img_to_array(image).reshape(1, img_size, img_size, 3)\n",
    "    prediction = model.predict(image)[0]\n",
    "    cat_percentage = round(prediction[0] * 100)\n",
    "    dog_percentage = round(prediction[1] * 100)\n",
    "    print(f\"This image seems {dog_percentage}% dog, and {cat_percentage}% cat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_dog.jpeg'\n",
    "\n",
    "show_and_predict_image(img_dir_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_cat.jpeg'\n",
    "\n",
    "show_and_predict_image(img_dir_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_cat.jpeg\"\n",
    "show_and_predict_image(img_dir_path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-14. í”„ë¡œì íŠ¸: ìƒˆë¡œìš´ ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚˜ë§Œì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° ë§Œë“¤ì–´ë³´ê¸°"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiffel_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
