{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20. 비지도학습\n",
    "\n",
    "**머신러닝의 학습 방법 중 하나인 비지도 학습(Unsupervised Learning)의 개념과 주요 알고리즘에 대해 알아본다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-1. 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-2. 비지도학습(Unsupervised Learning)에 대하여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-3. 클러스터링(1) K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 중심점이 5개인 100개의 점 데이터를 무작위로 생성합니다.\n",
    "points, labels = make_blobs(n_samples=100, centers=5, n_features=2, random_state=135)\n",
    "\n",
    "print(points.shape, points[:10])  # 무작위로 생성된 점의 좌표 10개 출력\n",
    "print(labels.shape, labels[:10])    # 10개의 점들이 각각 대응하는 중심점(label) 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 축 그리기\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# 위에서 생성한 점 데이터들을 pandas DataFrame 형태로 변환하기\n",
    "points_df = pd.DataFrame(points, columns=['X', 'Y'])\n",
    "display(points_df.head())\n",
    "\n",
    "# 점 데이터를 X-Y grid에 시각화하기\n",
    "ax.scatter(points[:, 0], points[:, 1], c='black', label='random generated data')\n",
    "\n",
    "# 축 이름을 라벨에 달고, 점 데이터 그리기\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1), 2) 위에서 생성한 무작위 점 데이터(points)에 클러스터의 수(K)가 5인 K-means 알고리즘을 적용 \n",
    "kmeans_cluster = KMeans(n_clusters=5)\n",
    "\n",
    "# 3) ~ 6) 과정이 전부 함축되어 있는 코드입니다. points에 대하여 K가 5일 때의 K-means iteration을 수행\n",
    "kmeans_cluster.fit(points)\n",
    "\n",
    "print(type(kmeans_cluster.labels_))\n",
    "print(np.shape(kmeans_cluster.labels_))\n",
    "print(np.unique(kmeans_cluster.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n 번째 클러스터 데이터를 어떤 색으로 도식할 지 결정하는 color dictionary\n",
    "color_dict = {0: 'red', 1: 'blue', 2:'green', 3:'brown', 4:'indigo'} \n",
    "\n",
    "# 점 데이터를 X-Y grid에 시각화합니다.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# K-means clustering의 결과대로 색깔별로 구분하여 점에 색칠한 후 도식\n",
    "for cluster in range(5):\n",
    "    cluster_sub_points = points[kmeans_cluster.labels_ == cluster] # 전체 무작위 점 데이터에서 K-means 알고리즘에 의해 군집화된 sub data를 분리합니다. \n",
    "    ax.scatter(cluster_sub_points[:, 0], cluster_sub_points[:, 1], c=color_dict[cluster], label='cluster_{}'.format(cluster)) # 해당 sub data를 plot합니다.\n",
    "\n",
    "# 축 이름을 라벨에 달고, 점 데이터 그리기\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means algorithm이 잘 동작하지 않는 예시 (1) 원형 분포\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# 원형 분포 데이터 생성\n",
    "circle_points, circle_labels = make_circles(n_samples=100, factor=0.5, noise=0.01) # 원형 분포를 가지는 점 데이터 100개를 생성합니다.\n",
    "\n",
    "# 캔버스 생성\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# 원형 분포에 대해 K-means 수행\n",
    "circle_kmeans = KMeans(n_clusters=2)\n",
    "circle_kmeans.fit(circle_points)\n",
    "color_dict = {0: 'red', 1: 'blue'}\n",
    "for cluster in range(2):\n",
    "    cluster_sub_points = circle_points[circle_kmeans.labels_ == cluster]\n",
    "    ax.scatter(cluster_sub_points[:, 0], cluster_sub_points[:, 1], c=color_dict[cluster], label='cluster_{}'.format(cluster))\n",
    "ax.set_title('K-means on circle data, K=2')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend() \n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means algorithm이 잘 동작하지 않는 예시 (2) 달 모양 분포\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# 달 모양 분포의 데이터 생성\n",
    "moon_points, moon_labels = make_moons(n_samples=100, noise=0.01) # 달 모양 분포를 가지는 점 데이터 100개를 생성합니다.\n",
    "\n",
    "# 캔버스 생성\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# 달 모양 분포 데이터 plot\n",
    "moon_kmeans = KMeans(n_clusters=2)\n",
    "moon_kmeans.fit(moon_points)\n",
    "color_dict = {0: 'red', 1: 'blue'}\n",
    "for cluster in range(2):\n",
    "    cluster_sub_points = moon_points[moon_kmeans.labels_ == cluster]\n",
    "    ax.scatter(cluster_sub_points[:, 0], cluster_sub_points[:, 1], c=color_dict[cluster], label='cluster_{}'.format(cluster))\n",
    "ax.set_title('K-means on moon-shaped data, K=2')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend() \n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means algorithm이 잘 동작하지 않는 예시 (3) 대각선 모양 분포\n",
    "from sklearn.datasets import make_circles, make_moons, make_blobs\n",
    "\n",
    "# 대각선 모양 분포의 데이터 생성\n",
    "diag_points, _ = make_blobs(n_samples=100, random_state=170) #대각선 분포를 가지는 점 데이터 100개를 생성합니다.(현재는 무작위 분포)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]] #대각선 변환을 위한 대각 행렬\n",
    "diag_points = np.dot(diag_points, transformation) #본 과정을 통해 무작위 분포의 점 데이터를 대각선 분포로 변환합니다.\n",
    "\n",
    "# 캔버스 생성\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# 대각선 모양 분포 데이터 plot\n",
    "diag_kmeans = KMeans(n_clusters=3)\n",
    "diag_kmeans.fit(diag_points)\n",
    "color_dict = {0: 'red', 1: 'blue', 2: 'green'}\n",
    "for cluster in range(3):\n",
    "    cluster_sub_points = diag_points[diag_kmeans.labels_ == cluster]\n",
    "    ax.scatter(cluster_sub_points[:, 0], cluster_sub_points[:, 1], c=color_dict[cluster], label='cluster_{}'.format(cluster))\n",
    "ax.set_title('K-means on diagonal-shaped data, K=2')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend() \n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-4. 클러스터링(2) DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN으로 circle, moon, diagonal shaped data를 군집화한 결과\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "fig = plt.figure()\n",
    "ax= fig.add_subplot(1, 1, 1)\n",
    "color_dict = {0: 'red', 1: 'blue', 2: 'green', 3:'brown',4:'purple'} # n 번째 클러스터 데이터를 어떤 색으로 도식할 지 결정하는 color dictionary\n",
    "\n",
    "# 원형 분포 데이터 plot\n",
    "epsilon, minPts = 0.2, 3 # 2)와 3) 과정에서 사용할 epsilon, minPts 값을 설정\n",
    "circle_dbscan = DBSCAN(eps=epsilon, min_samples=minPts) # 위에서 생성한 원형 분포 데이터에 DBSCAN setting\n",
    "circle_dbscan.fit(circle_points) # 3) ~ 5) 과정을 반복\n",
    "n_cluster = max(circle_dbscan.labels_)+1 # 3) ~5) 과정의 반복으로 클러스터의 수 도출\n",
    "\n",
    "print(f'# of cluster: {n_cluster}')\n",
    "print(f'DBSCAN Y-hat: {circle_dbscan.labels_}')\n",
    "\n",
    "# DBSCAN 알고리즘의 수행결과로 도출된 클러스터의 수를 기반으로 색깔별로 구분하여 점에 색칠한 후 도식\n",
    "for cluster in range(n_cluster):\n",
    "    cluster_sub_points = circle_points[circle_dbscan.labels_ == cluster]\n",
    "    ax.scatter(cluster_sub_points[:, 0], cluster_sub_points[:, 1], c=color_dict[cluster], label='cluster_{}'.format(cluster))\n",
    "ax.set_title('DBSCAN on circle data')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 달 모양 분포 데이터 plot - 위와 같은 과정 반복\n",
    "fig = plt.figure()\n",
    "ax= fig.add_subplot(1, 1, 1)\n",
    "color_dict = {0: 'red', 1: 'blue', 2: 'green', 3:'brown',4:'purple'} # n 번째 클러스터 데이터를 어떤 색으로 도식할 지 결정하는 color dictionary\n",
    "\n",
    "epsilon, minPts = 0.4, 3\n",
    "moon_dbscan = DBSCAN(eps=epsilon, min_samples=minPts)\n",
    "moon_dbscan.fit(moon_points)\n",
    "n_cluster = max(moon_dbscan.labels_)+1\n",
    "\n",
    "print(f'# of cluster: {n_cluster}')\n",
    "print(f'DBSCAN Y-hat: {moon_dbscan.labels_}')\n",
    "\n",
    "for cluster in range(n_cluster):\n",
    "    cluster_sub_points = moon_points[moon_dbscan.labels_ == cluster]\n",
    "    ax.scatter(cluster_sub_points[:, 0], cluster_sub_points[:, 1], c=color_dict[cluster], label='cluster_{}'.format(cluster))\n",
    "ax.set_title('DBSCAN on moon data')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대각선 모양 분포 데이터 plot - 위와 같은 과정 반복\n",
    "fig = plt.figure()\n",
    "ax= fig.add_subplot(1, 1, 1)\n",
    "color_dict = {0: 'red', 1: 'blue', 2: 'green', 3:'brown',4:'purple'} # n 번째 클러스터 데이터를 어떤 색으로 도식할 지 결정하는 color dictionary\n",
    "\n",
    "epsilon, minPts = 0.7, 3\n",
    "diag_dbscan = DBSCAN(eps=epsilon, min_samples=minPts)\n",
    "diag_dbscan.fit(diag_points)\n",
    "n_cluster = max(diag_dbscan.labels_)+1\n",
    "\n",
    "print(f'# of cluster: {n_cluster}')\n",
    "print(f'DBSCAN Y-hat: {diag_dbscan.labels_}')\n",
    "\n",
    "for cluster in range(n_cluster):\n",
    "    cluster_sub_points = diag_points[diag_dbscan.labels_ == cluster]\n",
    "    ax.scatter(cluster_sub_points[:, 0], cluster_sub_points[:, 1], c=color_dict[cluster], label='cluster_{}'.format(cluster))\n",
    "ax.set_title('DBSCAN on diagonal shaped data')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN 알고리즘과 K-means 알고리즘의 시간을 비교하는 코드 \n",
    "import time\n",
    "\n",
    "n_samples= [100, 500, 1000, 2000, 5000, 7500, 10000, 20000, 30000, 40000, 50000]\n",
    "\n",
    "kmeans_time = []\n",
    "dbscan_time = []\n",
    "x = []\n",
    "for n_sample in n_samples:\n",
    "    dummy_circle, dummy_labels = make_circles(n_samples=n_sample, factor=0.5, noise=0.01) # 원형의 분포를 가지는 데이터 생성\n",
    "\n",
    "    # K-means 시간을 측정\n",
    "    kmeans_start = time.time()\n",
    "    circle_kmeans = KMeans(n_clusters=2)\n",
    "    circle_kmeans.fit(dummy_circle)\n",
    "    kmeans_end = time.time()\n",
    "\n",
    "    # DBSCAN 시간을 측정\n",
    "    dbscan_start = time.time()\n",
    "    epsilon, minPts = 0.2, 3\n",
    "    circle_dbscan = DBSCAN(eps=epsilon, min_samples=minPts)\n",
    "    circle_dbscan.fit(dummy_circle)\n",
    "    dbscan_end = time.time()\n",
    "\n",
    "    x.append(n_sample)\n",
    "    kmeans_time.append(kmeans_end-kmeans_start)\n",
    "    dbscan_time.append(dbscan_end-dbscan_start)\n",
    "    print(\"# of samples: {} / Elapsed time of K-means: {:.5f}s / DBSCAN: {:.5f}s\".format(n_sample, kmeans_end-kmeans_start, dbscan_end-dbscan_start))\n",
    "\n",
    "# K-means와 DBSCAN의 소요 시간 그래프화\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(x, kmeans_time, c='red', marker='x', label='K-means elapsed time')\n",
    "ax.scatter(x, dbscan_time, c='green', label='DBSCAN elapsed time')\n",
    "ax.set_xlabel('# of samples')\n",
    "ax.set_ylabel('time(s)')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-5. 차원 축소(1) PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차원 축소 예제: 유방암 데이터셋\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 로드\n",
    "cancer=load_breast_cancer()\n",
    "\n",
    "# y=0(Malignant:악성 종양), y=1(Benign:양성 종양)\n",
    "cancer_X, cancer_y= cancer.data, cancer['target']\n",
    "train_X, test_X, train_y, test_y = train_test_split(cancer_X, cancer_y, test_size=0.1, random_state=10) # train 데이터셋과 test 데이터셋으로 나눔\n",
    "print(\"전체 검사자 수: {}\".format(len(cancer_X)))\n",
    "print(\"Train dataset에 사용되는 검사자 수: {}\".format(len(train_X)))\n",
    "print(\"Test dataset에 사용되는 검사자 수: {}\".format(len(test_X)))\n",
    "cancer_df = pd.DataFrame(cancer_X, columns=cancer['feature_names'])\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "# color dictionary\n",
    "color_dict = {0: 'red', 1: 'blue', 2:'red', 3:'blue'}\n",
    "target_dict = {0: 'malignant_train', 1: 'benign_train', 2: 'malignant_test', 3:'benign_test'}\n",
    "\n",
    "#Train data에 PCA 알고리즘 적용\n",
    "train_X_ = StandardScaler().fit_transform(train_X) # 불러온 데이터에 대한 정규화 -> 각 column의 range of value가 전부 다르기 때문에 정규화를 진행해 주어야 합니다.\n",
    "train_df = pd.DataFrame(train_X_, columns=cancer['feature_names'])\n",
    "pca = PCA(n_components=2) # 주성분의 수를 2개, 즉 기저가 되는 방향벡터를 2개로 하는 PCA 알고리즘 수행\n",
    "pc = pca.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data에 PCA 알고리즘 적용\n",
    "test_X_ = StandardScaler().fit_transform(test_X) # normalization\n",
    "test_df = pd.DataFrame(test_X_, columns=cancer['feature_names'])\n",
    "pca_test = PCA(n_components=2)\n",
    "pc_test = pca_test.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련한 classifier의 decision boundary를 그리는 함수\n",
    "def plot_decision_boundary(X, clf, ax): \n",
    "    h = .02  # step size in the mesh\n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contour(xx, yy, Z, cmap='Blues')\n",
    "\n",
    "# PCA를 적용한 train data의 classifier 훈련: classfier로 Support Vector Machine(SVM) 사용\n",
    "clf = svm.SVC(kernel = 'rbf', gamma=0.5, C=0.8) # 여기서는 classifier로 SVM을 사용한다는 정도만 알아둡시다!\n",
    "clf.fit(pc, train_y) # train data로 classifier 훈련\n",
    "\n",
    "# PCA를 적용하지 않은 original data의 SVM 훈련\n",
    "clf_orig = svm.SVC(kernel = 'rbf', gamma=0.5, C=0.8) # 여기서는 classifier로 SVM을 사용한다는 정도만 알아둡시다!\n",
    "clf_orig.fit(train_df, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캔버스 도식\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# malignant와 benign의 SVM decision boundary 그리기\n",
    "plot_decision_boundary(pc, clf, ax)\n",
    "\n",
    "#Train data 도식\n",
    "for cluster in range(2):\n",
    "    sub_cancer_points = pc[train_y == cluster]\n",
    "    ax.scatter(sub_cancer_points[:, 0], sub_cancer_points[:, 1], edgecolor=color_dict[cluster], c='none', label=target_dict[cluster])\n",
    "#Test data 도식\n",
    "for cluster in range(2):\n",
    "    sub_cancer_points = pc_test[test_y == cluster]\n",
    "    ax.scatter(sub_cancer_points[:, 0], sub_cancer_points[:, 1], marker= 'x', c=color_dict[cluster+2], label=target_dict[cluster+2])\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('PCA-Breast cancer dataset')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "# Scoring\n",
    "pca_test_accuracy_dict = Counter(clf.predict(pc_test) == test_y)\n",
    "orig_test_accuracy_dict = Counter(clf_orig.predict(test_df) == test_y)\n",
    "\n",
    "print(\"PCA 분석을 사용한 Test dataset accuracy: {}명/{}명 => {:.3f}\".format(pca_test_accuracy_dict[True], sum(pca_test_accuracy_dict.values()), clf.score(pc_test, test_y)))\n",
    "print(\"PCA를 적용하지 않은 Test dataset accuracy: {}명/{}명 => {:.3f}\".format(orig_test_accuracy_dict[True], sum(orig_test_accuracy_dict.values()), clf_orig.score(test_df, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-6. 차원 축소(2) T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"실행 중입니다... 시간이 다소 걸릴 수 있어요. :)\\n===\")\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# 784 pixel로 이뤄진 mnist 이미지 데이터 호출\n",
    "mnist = fetch_openml(\"mnist_784\",version=1)\n",
    "\n",
    "X = mnist.data / 255.0\n",
    "y = mnist.target\n",
    "print(\"X shape: \",X.shape)\n",
    "print(\"Y shape: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image = X.shape[0]\n",
    "n_image_pixel = X.shape[1]\n",
    "\n",
    "pixel_columns = [ f\"pixel{i}\" for i in range(1, n_image_pixel + 1) ] #  픽셀정보가 있는 칼럼의 이름을 담은 목록\n",
    "len(pixel_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X,columns=pixel_columns)\n",
    "df['y'] = y\n",
    "df['label'] = df['y'].apply(lambda i: str(i)) # 숫자 라벨을 스트링으로 만드는 함수를 파이썬 람다 문법으로 전체 데이터에 적용합니다.\n",
    "X, y = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 결과가 재생산 가능하도록 랜덤 시드를 지정합니다.\n",
    "np.random.seed(30)\n",
    "\n",
    "# 이미지 데이터의 순서를 랜덤으로 뒤바꾼(permutation) 배열을 담습니다.\n",
    "rndperm = np.random.permutation(n_image)\n",
    "\n",
    "# 랜덤으로 섞은 이미지 중 10,000개를 뽑고, df_subset에 담습니다.\n",
    "n_image_sample = 10000\n",
    "random_idx = rndperm[:n_image_sample]\n",
    "df_subset = df.loc[random_idx,:].copy()\n",
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gray()\n",
    "fig = plt.figure( figsize=(10,6) )\n",
    "n_img_sample = 15\n",
    "width,height = 28,28\n",
    "\n",
    "# 15개 샘플을 시각화해 봅니다. \n",
    "for i in range(0,n_img_sample):\n",
    "    row = df_subset.iloc[i]\n",
    "    ax = fig.add_subplot(3,5,i+1, title=f\"Digit: {row['label']}\")\n",
    "    ax.matshow(row[pixel_columns]\n",
    "               .values.reshape((width,height))\n",
    "               .astype(float))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"df_subset의 shape: {}\".format(df_subset.shape))\n",
    "\n",
    "n_dimension = 2 # 축소시킬 목표 차원의 수\n",
    "pca = PCA(n_components=n_dimension)\n",
    "\n",
    "pca_result = pca.fit_transform(df_subset[pixel_columns].values) # 차원을 축소한 결과\n",
    "df_subset['pca-one'] = pca_result[:,0] # 축소한 결과의 첫 번째 차원 값\n",
    "df_subset['pca-two'] = pca_result[:,1] # 축소한 결과의 두 번째 차원 값\n",
    "\n",
    "print(\"pca_result의 shape: {}\".format(pca_result.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"pca-1: {round(pca.explained_variance_ratio_[0],3)*100}%\")\n",
    "print(f\"pca-2: {round(pca.explained_variance_ratio_[1],3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df_subset,   # 2개의 PC축만 남은 데이터프레임 df_subset 을 시각화해 보자.\n",
    "    legend=\"full\",\n",
    "    alpha=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "print(\"df_subset의 shape: {}\".format(df_subset.shape))\n",
    "\n",
    "data_subset = df_subset[pixel_columns].values\n",
    "n_dimension = 2\n",
    "tsne = TSNE(n_components=n_dimension)\n",
    "tsne_results = tsne.fit_transform(data_subset)\n",
    "\n",
    "print(\"tsne_results의 shape: {}\".format(tsne_results.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne 결과를 차원별로 추가합니다.\n",
    "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "# 시각화해 봅니다.\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-7. 정리 및 요약"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ce9abe337a9e694d01ea52d504102083454ad8bd4b0e3a574e4432f4229329"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiffel_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
