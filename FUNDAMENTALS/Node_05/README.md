# 5. 날씨 좋은 월요일 오후 세 시, 자전거 타는 사람은 몇 명?

**Kaggle의 bike sharing 데이터셋을 이용해 기초적인 회귀 모델 활용 데이터분석 프로젝트를 진행한다.**

---

|-|목차|⏲ 330분|
|:---:|---|:---:|
|5-1| 들어가며 | 5분|
|5-2| 단 하나의 정보, "사용한 연수"만 가지고 맥북의 중고가 맞춰보기 (1) 맥북의 중고가를 결정짓는 변수는 무엇일까? 데이터 확인하기 | 10분|
|5-3| 단 하나의 정보, "사용한 연수"만 가지고 맥북의 중고가 맞춰보기 (2) "모델"을 만든다는 것, 그 의미 이해하기 | 15분|
|5-4| 단 하나의 정보, "사용한 연수"만 가지고 맥북의 중고가 맞춰보기 (3) 정확한 방정식이 아닌, "최적의 방정식"을 구하는 여정의 시작: 손실함수 정의하기 | 15분|
|5-5| 단 하나의 정보, "사용한 연수"만 가지고 맥북의 중고가 맞춰보기 (4) 모델을 점점 똑똑하게 만드는 방법? 손실함수를 줄이면 되겠지! | 15분|
|5-6| 단 하나의 정보, "사용한 연수"만 가지고 맥북의 중고가 맞춰보기 (5) 한 번에 못해도 괜찮아, 한 단계 한 단계 학습해나가면 되니까! | 15분|
|5-7| 이번엔 하나가 아니다! 다양한 정보로 원하는 값을 예측해 보기 (1) 손님의 성별, 수, 총 결제 금액 등으로 내가 받을 팁을 예측할 수 있을까? | 15분|
|5-8| 이번엔 하나가 아니다! 다양한 정보로 원하는 값을 예측해 보기 (2) 다시 한 번 직접 설계해 보는 손실함수 | 15분|
|5-9| 이번엔 하나가 아니다! 다양한 정보로 원하는 값을 예측해 보기 (3) 앞으로는 절대 해 볼 일 없을, 직접 그래디언트 계산하기 | 15분|
|5-10| 이번엔 하나가 아니다! 다양한 정보로 원하는 값을 예측해 보기 (4) 모두 준비 되었다면, 모델 학습은 간단하다구! | 15분|
|5-11| 이번엔 하나가 아니다! 다양한 정보로 원하는 값을 예측해 보기 (5) 지금까지 한 모든 과정을, 라이브러리로 깔끔하게 | 15분|
|5-12| 프로젝트 1 : 손수 설계하는 선형회귀, 당뇨병 수치를 맞춰보자! | 90분|
|5-13| 프로젝트 2 : 날씨 좋은 월요일 오후 세 시, 자전거 타는 사람은 몇 명? | 90분|

---

### 학습 전제

- numpy, pandas, matplotlib 등의 라이브러리를 자유롭게 활용할 수 있다.
- 원핫인코딩 등의 간단한 데이터 전처리 방식의 개념에 대해 알고있다.
- 고등 수학 과정 중 도함수의 정의와 미분계수 수식, 그리고 간단한 미분 공식을 알고 있다.
- 머신러닝의 개념과 그 패러다임에 관해 학습해본 적이 있으며, 낯설지 않다.

### 학습 목표

- 입력데이터인 X, 정답데이터인 y, 모델의 출력인 prediction 각각의 개념을 알고, y에 가까운 prediction을 낼 수 있도록 학습한다는 철학을 이해한다.
- 손실함수의 개념과 손실함수가 필요한 이유를 이해하고, 쓸 수 있는 함수의 종류와 구현을 익힌다.
- 손실함수를 미분해서 구하는 기울기는 손실함수값을 줄이기 위해 필요한 것임을 이해하고, 그 구현을 수치미분과 해석미분 두 가지 방법으로 진행해본다.
- 손실함수를 정의하고 경사하강법을 활용해 선형 방정식 형태로 된 모델을 학습시켜 실수형 데이터를 예측하는 선형 회귀 프로젝트의 전체 프로세스를 경험하고 익힌다.
- sklearn의 LinearRegression을 활용해 빠르고 간편하게 선형 회귀 하는 방법을 익힌다.

### 목차

- Step 1. 단 하나의 정보, "사용한 연수"만 가지고 맥북의 중고가 맞춰보기
  - (1) 맥북의 중고가를 결정짓는 변수는 무엇일까? 데이터 확인하기
  - (2) "모델"을 세운다는 것, 그에 대한 의미 이해하기
  - (3) 정확한 방정식이 아닌, "최적의 방정식"을 구하는 여정의 시작: 손실함수 정의하기
  - (4) 모델을 점점 똑똑하게 만드는 방법? 손실함수를 줄이면 되겠지!
  - (5) 한 번에 못해도 괜찮아, 한 단계 한 단계 학습해나가면 되니까!
- Step 2. 이번엔 하나가 아니다! 다양한 정보로 원하는 값을 예측해 보기
  - (1) 손님의 성별, 수, 전체 먹은 금액 등으로 내가 받을 팁을 예측할 수 있을까?
  - (2) 다시 한번 직접 설계해 보는 손실함수
  - (3) 앞으로는 절대 해 볼 일 없을, 직접 그래디언트 계산하기
  - (4) 모두 준비 되었다면, 모델 학습은 간단하죠!
  - (5) 지금까지 한 모든 과정을, 라이브러리로 깔끔하게

#### 프로젝트 1 : 손수 설계하는 선형회귀, 당뇨병 수치를 맞춰보자

- (1) 데이터 가져오기
- (2) 모델에 입력할 데이터 X 준비하기
- (3) 모델에 예측할 데이터 y 준비하기
- (4) train 데이터와 test 데이터로 분리하기
- (5) 모델 준비하기
- (6) 손실함수 loss 정의하기
- (7) 기울기를 구하는 gradient 함수 구현하기
- (8) 하이퍼 파라미터인 학습률 설정하기
- (9) 모델 학습하기
- (10) test 데이터에 대한 성능 확인하기
- (11) 정답 데이터와 예측한 데이터 시각화하기

#### 프로젝트 2 : 날씨 좋은 월요일 오후 세 시, 자전거 타는 사람은 몇 명?

- (1) 데이터 가져오기
- (2) datetime 컬럼을 datetime 자료형으로 변환하고 연, 월, 일, 시, 분, 초까지 6가지 컬럼 생성하기
- (3) year, month, day, hour, minute, second 데이터 개수 시각화하기
- (4) X, y 컬럼 선택 및 train/test 데이터 분리
- (5) LinearRegression 모델 학습
- (6) 학습된 모델로 X_test에 대한 예측값 출력 및 손실함수값 계산
- (7) x축은 temp 또는 humidity로, y축은 count로 예측 결과 시각화하기

---

- 상관관계
  - import numpy as np
  - np.corrcoef(x,y)
  - 두 변수 간의 패턴을 나타내는 것이 아닌, 각 값의 증가 또는 감소에 대한 관계만을 나타냄 => 기울기와 아무 상관이 없다!
  - 상관계수
    - 상관계수 = 0: 상관관계 없음
    - 상관계수 절댓값 증가: 상관관계 강함
      - 상관계수 > 0: 한 변수가 커질수록 다른 변수도 커짐
      - 상관계수 < 0: 한 변수가 커질수록 다른 변수는 작아짐
  - 데이터 분포
    - 직선에 가까울수록 상관계수 절댓값 1에 가까워짐 => 상관관계 강함
    - 원에 가까울수록 상관계수 값 0에 가까워짐 => 상관관계 없음
  - 인과관계랑 다름!
- 모델(model)
  - 특정 정보를 입력받아서 그 정보에 따라 원하는 값을 예측하여 값을 출력하는 함수
  - 최적의 함수(일차함수, y=wx+b) 찾기
    - **손실함수(loss function)** == 비용함수(cost function)
      - y - $\hat y$
      - error = price - prediction
      - 모델이 예측하는 출력값(=예측값)과 정답값 간의 거리를 나타내는 함수
      - 손실값(loss)이 작을수록 올바른 예측을 하고 있다는 의미 => loss=0일 때 w 구하기! => 경사하강법(Gradient Descent Method) 사용
    - 모델이 얼마나 틀렸는지 평가하는 지표: MAE, MSE, RMSE, R-squared
      - 특히 많이 사용되는 지표: RMSE($\sqrt{MSE}$)
    - **경사하강법(Gradient Descent Method)**
      - **최적의 w 값이 무엇인지를 모르기 때문에, 현재 w 값 또한 최적의 w보다 큰지 혹은 작은지를 알 수 없다. => 기울기(gradient) 이용**
      - 과정
        - 현재 w 에서의 기울기 구하기
        - 기울기의 음수/양수를 보고 w 갱신
          - gradient = 0 이 되는 w 를 찾아야 함!
          - gradient > 0 이면 최적의 w 보다 오른쪽에 있다는 의미 => w 를 작은 값으로 갱신해야 함
          - gradient < 0 이면 최적의 w 보다 왼쪽에 있다는 의미 => w 를 큰 값으로 갱신해야 함
      - **w' = w - αg**
        - w': 새로운 w
        - w: 현재 w
        - α: 학습률(얼마나 업데이트할 것인지 결정하는 상수) => 얼마나 키울지/줄일지 배율 결정
        - g: 기울기(gradient) => 키울지/줄일지 방향/크기 결정
  - 파라미터
    - 파라미터: 모델이 스스로 학습해 나가는 파라미터
      - 학습률: 복잡한 데이터셋에서는 보통 0.0001 ~ 0.01 정도로 작은 값 사용
    - 하이퍼 파라미터: 사람이 직접 사전에 정하고 시작해야 하는 파라미터
  - epoch 이 너무 커도 문제 => 과적합(Overfitting) 발생
- 시각화 라이브러리
  - matplotlib
  - seaborn
- 원-핫 인코딩(One Hot Encoding)
  - 카테고리 데이터 -> 숫자 데이터로 변환
  - pandas.get_dummies()
- 선형 방정식 == 다변수 일찹아정식
  - 각각의 x에 개별 가중치를 곱함
  - 선형 회귀: 선형 방정식을 통해 회귀 문제를 푼다. => 값을 예측한다.
- 분류 <-> 회귀
  - 분류: 맞추고자 하는 값 - 카테고리
  - 회귀: 맞추고자 하는 값 - 연속된 실수값
- 데이터
  - from sklearn.model_selection import train_test_split
  - X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  - train 데이터와 test 데이터로 분리
- 모델 설계, 손실함수 정의, 기울기 계산 및 최적화 과정을 sklearn으로 진행
  - from sklearn.linear_model import LinearRegression
  - from sklearn.metrics import mean_squared_error
  - model = LinearRegression()  # 모델 준비
  - model.fit(X_train, y_train)  # 학습
  - predictions = model.predict(X_test)  # 예측
  - mse = mean_squared_error(y_test, predictions)  # 성능 평가(MSE 사용)

---

- 입력데이터인 X, 정답데이터인 y, 모델의 출력인 prediction, 각각의 개념을 알고, 정답데이터에 가까운 출력을 낼 수 있도록 학습한다는 철학을 이해해 보았고,
- 손실함수의 개념과 손실함수가 필요한 이유를 이해하고, 쓸 수 있는 함수의 종류를 알아보았으며 직접 구현해 보았습니다.
- 또한, 손실함수를 미분해서 구하는 기울기는 손실함수값을 줄이기 위해 필요한 것임을 이해하고, 그 구현을 수치미분과 해석미분 두 가지 방법으로 진행했죠.
- 그리고, 선형 방정식 형태로 된 모델을 학습시켜 실수형 데이터를 예측하는 선형 회귀 프로젝트의 전체 프로세스를 경험하고 익혀보았습니다.
- 마지막으로는 사이킷런을 활용해서 간편하고 빠르게 선형 회귀를 진행해 보기도 했어요!
