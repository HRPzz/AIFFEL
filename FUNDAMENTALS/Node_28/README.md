# 28. 정보이론 톺아보기

**머신러닝의 가장 중요한 이론 중 하나인 정보이론(Information Theory)의 주요 개념인 Entropy, Cross Entropy, KL divergence 등의 개념을 파악하고, 이런 개념들이 머신러닝 이론과 어떻게 연결되는지의 사례를 알아본다.**

---

|-|목차|⏲ 120분|
|:---:|---|:---:|
|28-1| 들어가며 | 5분|
|28-2| Information Content | 15분|
|28-3| Entropy | 20분|
|28-4| Kullback Leibler Divergence | 20분|
|28-5| Cross Entropy Loss | 30분|
|28-6| Decision Tree와 Entropy | 30분|

---

## 학습 목표

머신러닝 이론의 이론적 토대를 이루는 가장 중요한 이론 중 하나인 정보이론(Information Theory)에 대해 알아본다. 또한 머신러닝에서 많이 사용되는 Entropy, Cross Entropy, KL divergence 등의 개념과 이런 개념들이 머신러닝 이론과 연결되는 사례를 파악해 본다.

## 학습 내용

1. Information Content
2. Entropy
3. Kullback Leibler Divergence
4. Cross Entropy Loss
5. Decision Tree와 Entropy

---
